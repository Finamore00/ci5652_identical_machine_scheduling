# CI5652 - Identical Machine Scheduling
Proyecto de Dise√±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad Sim√≥n Bol√≠var.

## üìù Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ü§î Descripci√≥n del problema
Dado un conjunto de `n` tareas y `m` m√°quinas id√©nticas, el objetivo es asignar cada tarea a una m√°quina y determinar la secuencia de tareas en cada m√°quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaci√≥n del trabajo `j`.

# üìã INFORME DEL PROYECTO - TERCER CORTE
El programa est√° implementado en C++ y consta de los siguientes archivos para este tercer corte:

- `memetic.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo mem√©tico para el problema.
- `aco.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo de optimicaci√≥n de colonia de hormigas para el problema.
- `scattered.cpp`: Archivo principal del programam que contiene la implementaci√≥n de la metaheur√≠stica de b√∫squeda dispersa aplicada al problema a tratar.

üìÇ En la carpeta `benchmarks` se encuentran los casos de pruebas de la primera corte del proyecto para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## Definici√≥n del operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres, el m√©todo de mejora luego de la recombinaci√≥n y la implementaci√≥n del algoritmo mem√©tico

### üòÇ Algoritmo Mem√©tico ( Õ°¬∞ Õú ñ Õ°¬∞)

### üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶ Operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres

- **Operador de cruce utilizado en el algoritmo gen√©tico**: Cruce parcialmente mapeado.

- **Cruce parcialmente mapeado para m√∫ltiples padres**: Se implementa el cruce parcialmente mapeado para m√∫ltiples padres, cuyo proceso consiste en:

    1. Sea `k` el n√∫mero de padres. 

    2. Se seleccionan aleatoriamente `k` puntos de corte para dividir cada padre en `k + 1` subpartes. 

    ![Ejemplo de subpartes](./img/ejemplo_subpartes.png)

      La √∫ltima subparte lo vamos a tomar en cuenta como subparte 1 tambi√©n.

    3. Se crea una lista de mapeo (`ch_map`) utilizando la funci√≥n `create_mapping_list`. Esta lista mapea los genes (o tareas) de diferentes padres entre s√≠. 

        3.1. Sea `g` el n√∫mero de genes o tareas de un individuo.

        3.2. Se crea un arreglo `job_mapped` para rastrear qu√© tareas ya han sido mapeados y un contador de tareas mapeados `cnt_mapped`

        3.3. Se selecciona aleatoriamente un padre `start_parent` y un gen inicial del padre seleccionado `start_gene`.

        3.4. Luego se ejecuta un bucle con `g` iteraciones
        
            3.4.1. En el bucle, se marca la tarea del gen actual `start_gene` como mapeado.

            3.4.2. Se selecciona un padre final `end_parent` aleatoriamente y diferente del padre inicial y se busca en el padre final el gen que corresponde a la misma tarea que el gen inicial, al encontrarlo se guarda el gen en `end_gene`.

            3.4.3. Se incrementa `cnt_mapped` a 1. Si todos las tareas han sido mapeados, se sale del bucle.

            3.4.4. Si a√∫n faltan tareas por mapear o marcar, se elige un nuevo padre inicial diferente del final y se selecciona un nuevo gen inicial cuyo gen tarea no haya sido marcada a√∫n.

            3.4.5. Y se agrega un mapeo con `ch_map[end_gene.job->id] = start_gene`

        3.5. Despu√©s del bucle, se agrega un mapeo final de la tarea del √∫ltimo gen a la tarea del gen inicial (el primer gen que se mapea). Esto para crear un mapeo c√≠clico entre tareas.

        ![Mapeo de genes](./img/mapeo_genes.png)

    4. Luego, se crea un orden aleatorio en los genes para cada subparte con la funci√≥n `create_random_order` y este orden aleatorio se guarda en un arreglo `order`

    5. Se crean los `k` hijos.

    6. Primero cada hijo `i` se copia la primera subparte del padre `i` (antes del primer punto de corte y despu√©s del √∫ltimo punto de corte).

    7. Luego, para cada hijo `i`, las subpartes entre los puntos de corte se copian de otros padres en un patr√≥n diagonal.

    8. Posteriormente, se legaliza cada hijo para asegurar que no hayan trabajos duplicados.

        8.1. Se crea un nuevo orden aleatorio `new_order` para procesar las subpartes del hijo `i`.

        8.2. Se marcan inicialmente la primera subparte procesada, o sea, la primera subparte de cada hijo permanece igual.

        8.3. Para cada subparte restante seg√∫n el orden en `new_order`.

            8.3.1. Se revisa cada gen de la subparte actual seg√∫n el orden en `order`.

            8.3.2. Si la tarea ya est√° marcado (duplicado), se reemplaza con el trabajo mapeado seg√∫n la lista de mapeo (`ch_map`). Este proceso contin√∫a hasta encontrar un trabajo no marcado.
            
            8.3.3. Al encontrar un trabajo no marcado, se marca el nuevo trabajo y se actualiza el gen en el hijo actual.
 
            8.3.4. Se marca la subparte actual procesada.

        8.4. Se verifica que todas las tareas est√©n marcadas (para asegurar que no hayan tareas duplicadas y tampoco tareas faltantes).

    10. Se devuelven los hijos generados.

### üöÄ‚¨Ü Mejora luego de la recombinaci√≥n

Para este paso, se utiliza la b√∫squeda local implementada en la primera corte del proyecto.

1. Sea un hijo `h` producido en la recombinaci√≥n.

2. Se decodifica el genotipo del hijo `h` en un fenotipo v√°lido.

3. Luego, se le aplica la b√∫squeda local al fenotipo convertido.

4. Y por √∫ltimo, el resultado de la b√∫squeda local se transforma nuevamente en un genotipo.

### üõ†Ô∏è Par√°metros del algoritmo mem√©tico

Aparte de recibir las tareas y la cantidad de m√°quinas, y los par√°metros del algoritmo gen√©tico: 
- population_size: El tama√±o de la poblaci√≥n

- mutation_rate: El porcentaje de mutaci√≥n.

- max_iter: El m√°ximo n√∫mero de iteraciones o generaciones.

El algoritmo mem√©tico recibe adicionalmente los siguientes par√°metros:
- nro_parents_crossover: Un entero para la cantidad de padres para ser seleccionadas para la recombinaci√≥n en cada generaci√≥n.

- opt_freq: Un entero que indica la frequencia de aplicar la mejora con la b√∫squeda local. Responde a la pregunta de ¬øcada cu√°ntas generaciones se lanza la optimizaci√≥n?

- opt_rate: Un float para el porcentaje de aplicar la mejora en la b√∫squeda local sobre los descendientes. ¬øCu√°ntos invididuos generados son optimizados en cada generaci√≥n?

- random_opt_rate: Un valor booleano que indica si aplicar la b√∫squeda local con un porcentaje aleatorio en  cada generaci√≥n o aplicarlo seg√∫n el opt_rate. Y si es aleatorio, el valor del par√°metro es true, en caso contrario es false. Adem√°s, si es aleatorio, el valor de porcentaje para la b√∫squeda local en cada generaci√≥n debe ser mayor que 10%, esto para asegurar que siempre se aplique una cantidad significativa de optimizaci√≥n local.

### üë£ Pasos del algoritmo mem√©tico

Los primeros pasos del algoritmo mem√©tico son similares al algoritmo gen√©tico de la segunda corte del proyecto:

1. Se genera una poblaci√≥n aleatoria inicial.

2. Se ordena la poblaci√≥n por su fitness.

3. Luego, se comienza un bucle. Hasta que se terminen el m√°ximo n√∫mero de generaciones o se encuentre la soluci√≥n √≥ptima (un fitness igual a 0), se procede a: 

    3.1. Calcular el fitness de cada individuo y la suma del fitness total de la poblaci√≥n.

    3.2. Crear una nueva poblaci√≥n, el cual se generan nuevos individuos hasta llenar el 90% de la nueva poblaci√≥n. El 10% restante se completa con los mejores individuos de la poblaci√≥n anterior.

Ac√° el paso 3.2. cambia un poco para el algoritmo mem√©tico:

3.2.1. Se seleccionan m√∫ltiples padres usando la funci√≥n `choose_multi_parents`. La selecci√≥n de padres es la misma condici√≥n para el algoritmo gen√©tico.
> Si definimos f(i) como la aptitud del individuo i de la poblaci√≥n S, entonces la probabilidad p(i) de que i sea escogido como padre viene dada por: p(i) = 1 - f(i)/sum(f(j) for j in S) 

3.2.2. Se aplica el cruce parcialmente mapeado multi-parental.

Luego del paso 3.2, se continua dentro del bucle con los siguientes pasos:

3.3. Se aplica mutaci√≥n a los nuevos individuos generados 
> Mutaci√≥n: Reasigna el trabajo seleccionado dentro de una m√°quina a otra m√°quina aleatoriamente escogida.

3.4. Se optimiza la generaci√≥n si es que le toca optimizarse (`opt_freq`):
- Se determina cu√°ntos individuos optimizar (basado en `random_opt_rate` y `opt_rate`).
- Se aplica b√∫squeda local a los individuos seleccionados.

3.5. La nueva poblaci√≥n reemplaza a la anterior.

3.6. Se ordena la nueva poblaci√≥n por su aptitud o fitness.

3.7. Se repite desde el paso 3.1 a 3.6 hasta que se finalice el bucle.

## Definici√≥n de la medida de distancia entre soluciones, el re-enlazado de caminos para un porcentaje dado de los pares de puntos de referencia de cada "generaci√≥n", e implementaci√≥n del algoritmo de b√∫squeda dispersa.

### Definici√≥n de distancia entre individuos

Dados los genotipos de dos individuos, `g1` y `g2`, la distancia entre los individuos representados por estos genotipos se define como el n√∫mero de trabajos que est√°n asignados a m√°quinas diferentes dentro de los mismos. Explicando de manera resumida:

1. Para cada par `g = <job_id, machine>` en `g1` (recordar la definici√≥n de gen en la entrega anterior)
    * Encontrar el gen `g'` en `g2` tal que `g'.job_id == job_id`
    * Si `g'.machine != g.machine`, entonces sumar 1 a la distancia total

Inicialmente se consider√≥ hacer una versi√≥n alternativa donde si para dos individuos un trabajo estaba asignado en la misma m√°quina, pero el dicho trabajo estaba en *posiciones distintas* dentro de la m√°quina en cuesti√≥n, entonces se agregar√≠a un valor de `0.5` adicional a la distancia. Sin embargo, se descart√≥ la idea por temas de rendimiento.

### Construcci√≥n del Conjunto de Referencia para el algoritmo de B√∫squeda Dispersa

Para el algoritmo de B√∫squeda Dispersa implementado se decidi√≥ emplear conjuntos de referencia que toman en cuenta para su constituci√≥n tanto la diversidad de las soluciones como su calidad. Dado que es la idea fundamental del algoritmo, la diversidad se mantuvo como el determinante principal de los elementos que constituyen en conjunto.

En cada iteraci√≥n del algoritmo el conjunto de referencia es obtenido como un subconjunto de una *piscina de soluciones*, de tama√±o igual o mayor al del conjunto de referncia. Al momento de generar el conjunto inicial, la piscina est√° conformada por soluciones generadas aleatoriamente que son sometidas a una mejora mediante b√∫squeda local con el fin de aumentar la calidad general de los individuos involucrados; durante las iteraciones posteriores del algoritmo la piscina de soluciones est√° compuesta por la uni√≥n del conjunto de referencia mismo con el conjunto de soluciones hijas que salen resultado del proceso de cruce. Una vez tenida la piscina de soluciones el conjunto de referencia es construido de la siguiente manera:

1. Todas las soluciones en la piscina son ordenadas de acuerdo a su aptitud.
2. Se utilizan las soluciones m√°s aptas de la piscina para conformar el 10% inicial del conjunto de referencia. Las soluciones escogidas son posteriormente eliminadas de la piscina
3. Luego hasta lograr el tama√±o definido para el conjnunto de referencia
    1. Hallar, para cada elemento en la piscina, la m√≠nima distancia existente entre √©l y alguno de los elementos ya presentes en el conjunto de referencia
    2. De todos los elementos de la piscina, se escoge aquel que entre las distancias m√≠nimas calculadas, tenga la m√°s grande.
    3. Incluir el elemento escogido en el conjunto de referencia y eliminarlo de la piscina de soluciones

La proporci√≥n del 10% de individuos basados en un criterio de calidad est√° *hardwired* en el c√≥digo y fue escogida de manera arbitraria, sin embargo, se cree que podr√≠a ser de provecho explorar diferentes proporciones de calidad y diversidad para futuras iteraciones del algoritmo.

### Cruce e Intesificaci√≥n mediante Reenlazado de Caminos

Para la formaci√≥n de nuevas soluciones se utilizan los mismos mecanismos de selecci√≥n y cruce empleados en el algoritmo mem√©tico. Posteriormente, se emplea un proceso de intensificaci√≥n sobre el conjunto de soluciones generadas aplicando Reenlazado de Caminos sobre un porcentaje definido de los posibles pares existentes sobre el conjunto de soluciones descendientes (El porcentajede pares a explorar se pasa al algoritmo como par√°metro).

Dadas dos genotipos `g1` y `g2` representando dos individuos de la poblaci√≥n, el proceso de reenlazado de caminos funciona explorando un conjunto de soluciones intermedias que "conectan" a `g1` y `g2` a trav√©s de estructuras de vecindad. Para generar este camino eficientemente, el reenlazado de caminos es realizado efectuando intercambios y reasignaciones de m√°quinas en `g1` vorazmente con el fin de irlo asemejando a `g2` en cada paso del proceso. Concretamente, para dos individuos el reenlazado de caminos se ejecuta de la siguiente forma:

Para cada gen `g = <job_id, machine>` en el individuo objetivo

1. Ubicar el gen `g'` en el individuo de partida con el id de trabajo `job_id`
2. Si la posici√≥n de `g'` en el individuo de partida es distinta a la posici√≥n de `g` en el individuo objetivo, traer `g'` a la posici√≥n correcta mediante una operaci√≥n de intercambio y generar una soluci√≥n intermedia
3. Si la m√°quina a la cual est√° asignada el trabajo en `g'` difiere de la m√°quina a la que est√° asignado el trabajo en `g`, cambiar la m√°quina de `g'` a la encontada en `g` y generar una soluci√≥n intermedia.

Para cada una de las soluciones intermedias generadas se mide su aptitud y se mantiene almacenada la soluci√≥n m√°s apta encontrada hasta el momento (esto puede incluir a las mismas soluciones de partida y objetivo). Si al terminar de explorar todas las soluciones intermedias se encuentra una soluci√≥n mejor a las dos involucradas, una de ellas es reemplazada al azar por la nueva soluci√≥n m√°s apta. Este proceso es repetido hasta que se explora el porcentaje de pares establecido.

### Recapitulaci√≥n del algoritmo de B√∫squeda Dispersa

Para sintetizar, el algoritmo de B√∫squeda Dispersa Implementado se resume en las siguientes operaciones:

1. Generar un conjunto de soluciones aleatorias con el tama√±o de piscina definido
2. Mejorar cada una de estas soluciones con un proceso breve de b√∫squeda local (para esta implementaci√≥n concreta, se emplearon 60 iteraciones).
3. Construir el conjunto inicial de referencias
4. Hasta que la mejor soluci√≥n tenga morosidad 0 o se efect√∫en el m√°ximo de iteraciones
    1. Crear la nueva generaci√≥n de individuos mediante los operadores de selecci√≥n y cruce
    2. Sobre los individuos generados, intentar obtener mejores y m√°s diversas soluciones empleando reenlace de caminos sobre el porcentaje de pares definido como argumento.
    3. Actualizar el conjunto de referencias usando como piscina de soluciones la uni√≥n del conjunto actual con el conjunto de descendientes intensificado.
5. Retornar la mejor soluci√≥n hallada

## Definici√≥n del comportamiento de la feromona/heur√≠stica e implemente con ello una optimizaci√≥n de colonia de hormigas
### üêú Optimizaci√≥n de Colonia de Hormigas

#### Feromona 

- **Estructura**: Se implementa como una matriz bidimensional donde cada elemento œÑ[i][j] representa el nivel de feromona para asignar la tarea i a la m√°quina j.

- **Inicializaci√≥n**: Al comenzar, todos los valores de feromona se establecen en 1.0, indicando que inicialmente no hay preferencia por ninguna asignaci√≥n.

- **Actualizaci√≥n local**: Despu√©s de cada asignaci√≥n de tarea, se actualiza la feromona usando la f√≥rmula:
  œÑ[job][machine] = (1 - œÅ_local) * œÑ[job][machine] + œÅ_local * ŒîœÑ
  Donde ŒîœÑ es 1 dividido por el retraso m√°ximo calculado inicialmente y œÅ_local es un par√°metro que controla la tasa de evaporaci√≥n local.

- **Actualizaci√≥n global**: Al final de cada iteraci√≥n, se actualiza la feromona bas√°ndose en la mejor soluci√≥n encontrada:
  œÑ[i][j] = (1 - œÅ_global) * œÑ[i][j] + œÅ_global * (1 / mejor_retraso) 
    Donde œÅ_global es un par√°metro que controla la tasa de evaporaci√≥n global y mejor_retraso es el retraso total de la mejor soluci√≥n encontrada.

- **Uso**: En la selecci√≥n de tareas, la feromona se eleva a la potencia Œ± para ajustar su influencia en la decisi√≥n.

#### Heur√≠stica


- **C√°lculo**: Se define como el inverso del retraso modificado de la fecha de vencimiento (modified due date tardiness o MDD):
  Œ∑ = 1 / MDD(tiempo_actual_m√°quina, tarea)

- **Funci√≥n MDD**: Calcula el retraso potencial de una tarea si se asignara a una m√°quina en un momento dado. 

- **Uso**: En la selecci√≥n de tareas, la heur√≠stica se eleva a la potencia Œ≤ para ajustar su influencia en la decisi√≥n.

- **Equilibrio con la feromona**: La probabilidad de seleccionar una tarea para una m√°quina se calcula como:
  P[i][j] ‚àù (œÑ[i][j])^Œ± * (Œ∑[i][j])^Œ≤
  Donde œÑ es la feromona, Œ∑ es la heur√≠stica, y Œ± y Œ≤ son par√°metros que controlan la importancia relativa de la feromona y la heur√≠stica respectivamente.

Esta combinaci√≥n de feromona y heur√≠stica permite al algoritmo equilibrar entre explotar la informaci√≥n aprendida (a trav√©s de la feromona) y responder a las caracter√≠sticas espec√≠ficas de cada tarea y el estado actual de las m√°quinas (a trav√©s de la heur√≠stica). Esto gu√≠a al algoritmo hacia soluciones que minimizan el retraso total de las tareas, adapt√°ndose din√°micamente a medida que construye y mejora las soluciones.

#### Pasos del Algoritmo

1. **Inicializaci√≥n**

El algoritmo comienza creando la matriz de feromonas. Adem√°s, se calcula el MDD Tardiness que se usa como referencia para la actualizaci√≥n local de la feromona. 

2. **Ciclo principal**

El coraz√≥n del algoritmo es un ciclo que se repite un n√∫mero fijo de veces. Cada repetici√≥n de este ciclo representa una generaci√≥n completa de soluciones. Durante cada iteraci√≥n, el algoritmo generar√° una soluci√≥n, la mejorar√°, y usar√° la informaci√≥n obtenida para influir en las siguientes generaciones.

3. **Construcci√≥n de soluciones**

En esta fase, el algoritmo crea m√∫ltiples soluciones desde cero. Cada soluci√≥n se construye de manera similar a c√≥mo una hormiga construir√≠a un camino. Se comienza con todas las tareas sin asignar y todas las m√°quinas vac√≠as. Luego, para cada tarea, se selecciona primero una m√°quina, favoreciendo aquellas con menos tiempo de procesamiento acumulado. Despu√©s, se elige una tarea para esa m√°quina, bas√°ndose en los niveles de feromona (que indican qu√© tan buena ha sido esta asignaci√≥n en el pasado) y la urgencia de la tarea. Una vez hecha la asignaci√≥n, se actualiza el tiempo de procesamiento de la m√°quina y se modifica ligeramente el nivel de feromona para esa combinaci√≥n espec√≠fica de tarea y m√°quina.

4. **Actualizaci√≥n local de feromonas**

Despu√©s de asignar cada tarea a una m√°quina, el algoritmo actualiza los niveles de feromona localmente. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que se han asignado en esta soluci√≥n.

5. **Mejora local**

Una vez construida una soluci√≥n completa, el algoritmo intenta mejorarla. Esto se hace mediante un proceso de b√∫squeda local.

6. **Evaluaci√≥n**

Despu√©s de mejorar cada soluci√≥n, el algoritmo calcula su calidad midiendo el retraso total que produce. Si esta soluci√≥n resulta ser mejor que la mejor encontrada hasta ahora (es decir, si produce un retraso total menor), se guarda como la nueva mejor soluci√≥n. 

7. **Actualizaci√≥n global de feromonas**

Al final de cada iteraci√≥n, despu√©s de haber construido y evaluado todas las soluciones de esa generaci√≥n, el algoritmo actualiza la matriz de feromonas bas√°ndose en la mejor soluci√≥n encontrada. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que aparecen en la mejor soluci√≥n.

8. **Evaporaci√≥n de feromonas**

Para evitar que el algoritmo se quede atrapado en soluciones sub√≥ptimas, se implementa un mecanismo de evaporaci√≥n de feromonas. Esto significa que en cada iteraci√≥n, todos los niveles de feromona se reducen ligeramente.

9. **Finalizaci√≥n**

Despu√©s de completar todas las iteraciones programadas, el algoritmo termina y devuelve la mejor soluci√≥n que ha encontrado. Esta soluci√≥n representa la programaci√≥n de tareas que, seg√∫n el algoritmo, deber√≠a producir el menor retraso total posible dado el conjunto de tareas y m√°quinas disponibles.

## üöÄ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./PROY3 <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el n√∫mero del algoritmo a ejecutar:

1. Algoritmo Mem√©tico
2. B√∫squeda Dispersa
3. Optimizaci√≥n de Colonia de Hormigas

## üìÑ Analisis de resultados

A continuaci√≥n se presenta el an√°lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomar√° en cuenta los valores de tardanza √≥ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados de ambos cortes del proyecto.


### üìä M√©tricas Comparativas
Las m√©tricas claves en el an√°lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la Soluci√≥n √ìptima (Optimal Solution Difference)**: La diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima.
- **Tiempo en segundos (Time in seconds)**: El tiempo en segundos tomado por el algoritmo.

As√≠ mismo, se emplearon diferentes par√°metros para cada algoritmo implementado en este tercer corte:
**Par√°metros del Algoritmo Mem√©tico (MA)**:
 * population_size: Tama√±o de la poblaci√≥n.
 * mutation_rate: Probabilidad de mutaci√≥n.
 * max_iter: N√∫mero m√°ximo de iteraciones permitidas para el algoritmo.
 * nro_parent_crossover: N√∫mero de padres que estar√°n involucrados en el proceso de cruce.
 * opt_freq: Frecuencia con la que se aplicar√° b√∫squeda local para la mejora de individuos (medido en n√∫mero de generaciones).
 * opt_rate: Porcentaje de la poblaci√≥n que ser√° mejorado por b√∫squeda local en cada proceso de intensificaci√≥n.
 * random_opt_rate: Valor booleano que indica si el porcentaje de poblaci√≥n a mejorar ser√° aleatorio para cada proceso de intensificaci√≥n.

> MA1: population_size = 500, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 3, opt_freq = 2, opt_rate = 0.75, random_opt_rate = false

> MA2: population_size = 500, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 10, opt_freq = 2, opt_rate = 0.75, random_opt_rate = false

> MA3: population_size = 500, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 10, opt_freq = 1, opt_rate = 0.75, random_opt_rate = false

> MA4: population_size = 500, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 3, opt_freq = 1, opt_rate = 1, random_opt_rate = false

> MA5: population_size = 250, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 5, opt_freq = 2, opt_rate = 1, random_opt_rate = true

> MA6: population_size = 250, mutation_rate = 0.05, max_iter = 20, nro_parents_crossover = 5, opt_freq = 2, opt_rate = 1, random_opt_rate = false

**Par√°metros de la B√∫squeda Dispersa (SS)**:
 * max_pool_size: Tama√±o m√°ximo a emplear para la piscina de soluciones.
 * ref_set_size: Tama√±o del conjunto de referencias.
 * parent_count: N√∫mero de padres a emplear en el proceso de cruce
 * max_iter: N√∫mero m√°ximo de iteraciones a realizar
 * path_relinking_ptg: Porcentaje de pares a explorar para el reenlazado de caminos

> SS1: max_pool_size = 40, ref_set_size = 20, parent_count = 4, max_iter = 20, path_relinking_ptg = 0.3

> SS2: max_pool_size = 40, ref_set_size = 20, parent_count = 4, max_iter = 30, path_relinking_ptg = 0.3

> SS3: max_pool_size = 40, ref_set_size = 20, parent_count = 5, max_iter = 30, path_relinking_ptg = 0.3

> SS4: max_pool_size = 60, ref_set_size = 30, parent_count = 5, max_iter = 20, path_relinking_ptg = 0.3

> SS5: max_pool_size = 60, ref_set_size = 30, parent_count = 5, max_iter = 30, path_relinking_ptg = 0.3

> SS6: max_pool_size = 60, ref_set_size = 30, parent_count = 6, max_iter = 20, path_relinking_ptg = 0.3

**Par√°metros de la Optimizaci√≥n de Colonia de Hormigas (ACO)**:
 * iterations: N√∫mero m√°ximo de iteraciones a realizar
 * ants: N√∫mero de hormigas (soluciones) a generar en cada iteraci√≥n.
 * alpha: Importancia del camino de feromonas en la toma de decisiones de las hormigas.
 * beta: Importancia de la informaci√≥n heur√≠stica en la toma de decisiones de las hormigas.
 * qm0: Probabilidad de escoger el trabajo menos tard√≠o en vez de elegir probabil√≠sticamente.
 * qj0: Probabilidad de seleccionar el trabajo de mayor valor en vez de elegir probabil√≠sticamente.
 * rho_local: Taza de evaporaci√≥n local de la feromona.
 * rho_global: Taza de evaporaci√≥n global de la feromona.

> ACO1: iterations = 250, ants = 20, alpha = 1, beta = 3, qm0 = 0.9, qj0 = 0.9, rho_local = 0.01, rho_global = 0.01

> ACO2: iterations = 250, ants = 50, alpha = 1, beta = 3, qm0 = 0.9, qj0 = 0.9, rho_local = 0.01, rho_global = 0.01

> ACO3: iterations = 250, ants = 20, alpha = 1, beta = 3, qm0 = 0.9, qj0 = 0.9, rho_local = 0.1, rho_global = 0.1

> ACO4: iterations = 250, ants = 20, alpha = 3, beta = 1, qm0 = 0.9, qj0 = 0.9, rho_local = 0.01, rho_global = 0.01

> ACO5: iterations = 250, ants = 20, alpha = 1, beta = 3, qm0 = 0.7, qj0 = 0.7, rho_local = 0.01, rho_global = 0.01

> ACO6: iterations = 100, ants = 20, alpha = 1, beta = 3, qm0 = 0.9, qj0 = 0.9, rho_local = 0.01, rho_global = 0.01

### üìà Resultados
Los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` se encuentran en el directorio `results`, sin embargo, debido a la cantidad de datos obtenidos, se almacen√≥ los datos m√°s relevantes en el siguiente enlace: [Resultados](https://docs.google.com/spreadsheets/d/1uta3jDjtNU2J74XQsV7Od8gzj1OaBIcp_lE5jGSw7Gw/edit#gid=294798782)

A modo de resumen y para facilitar la visualizaci√≥n de los resultados, se presentan las siguentes im√°genes comparativas resumidas a continuaci√≥n:

#### Promedio de diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima cada n tareas y m m√°quinas
- Resultados del primer corte:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Diff Opt Corte1](./img/DiffOptCorte1.png)

- Resultados del segundo corte:
    - Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

    ![Diff Opt ILS &TS &SA](./img/DiffOptILS&TS&SA.png)

    - GRASP usando diferentes par√°metros:

    ![Diff Opt GRASP](./img/DiffOptGRASP.png)

    - Genetic Algorithm (GA) usando diferentes par√°metros:

    ![Diff Op tGA](./img/DiffOptGA.png)

- Resultados del tercer corte: 

    - Algoritmo Mem√©tico usando diferentes par√°metros:

    ![Diff Opt MA](./img/DiffOptMA.png)

    - B√∫squeda Dispersa usando diferentes par√°metros:

    ![Diff Opt SS](./img/DiffOptSS.png)

    - Optimizaci√≥n de Colonia de Hormigas usando diferentes par√°metros:

    ![Diff Opt ACO](./img/DiffOptACO.png)


#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20

![Sorted Diff opt by n = 20](./img/SortedDiffn20Corte3.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 25

![Sorted Diff opt by n = 25](./img/SortedDiffn25Corte3.png)

#### Promedio de tiempo en segundos para cada n tareas y m m√°quinas
- Resultados del primer corte:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Time Corte1](./img/TimeCorte1.png)

- Resultados del segundo corte:

    - Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

    ![Time ILS & TS & SA](./img/TimeILS&TS&SA.png)

    - GRASP usando diferentes par√°metros:

    ![Time GRASP](./img/TimeGRASP.png)

    - Genetic Algorithm (GA) usando diferentes par√°metros:

    ![Diff Op tGA](./img/TimeGA.png)


- Resultados del tercer corte: 

    - Algoritmo Mem√©tico usando diferentes par√°metros:

    ![Time MA](./img/TimeMA.png)

    - B√∫squeda Dispersa usando diferentes par√°metros:

    ![Time SS](./img/Time%20SS.png)

    - Optimizaci√≥n de Colonia de Hormigas usando diferentes par√°metros:

    ![Time ACO](./img/TimeACO.png)

#### Resultados ordenados por promedio de tiempo por n = 20

![Sorted Time by n = 20](./img/SortedTimen20Corte3.png)

#### Resultados ordenados por promedio de tiempo por n = 25

![Sorted Time by n = 25](./img/SortedTimen25Corte3.png)


## üìå Conclusiones

- **Seg√∫n el promedio de diferencias entre la soluci√≥n √≥ptima y la soluci√≥n obtenida**:
    - **Para n = 20** El algoritmo mem√©tico y la optimizaci√≥n de colonia de hormigas se posicionan como los algoritmos m√°s exactos de las soluciones implementadas, teniendo 3 y 2 posiciones de los 5 mejores resultados respectivamente. Se evidencia una clara p√©rdida de exactitud en el algoritmo de b√∫squeda dispersa, con todas sus ejecuciones quedando en los √∫ltimos 6 lugares del ranking. La p√©rdida de exactitud demostrada por el algorimto de b√∫squeda dispersa es adem√°s bastante pronunciada, con el *mejor* desempe√±o de la b√∫squeda dispersa (15.2844) siendo un 30.4% m√°s tard√≠o que el *peor* resultado del algoritmo mem√©tico (11.7217) y un 66.67% m√°s tard√≠o que el *peor* resultado de la optimizaci√≥n de colonia de hormigas (9.1724)

    - **Para n = 25** La optimizaci√≥n de colonia de hormigas muestra una clara superioridad por encima de las otras dos metaheur√≠sticas, teniendo la totalidad de los 5 mejores resultados obtenidos. Inmediatamente despu√©s le siguen casi todas las instancias del algoritmo mem√©tico, y finalmente la b√∫squeda dispersa vuelve a posicionarse como el algoritmo menos exacto. En este caso el *mejor* resultado de b√∫squeda dispersa (36.1084) es un 68.64% m√°s tard√≠o que el *peor* resultado del algoritmo mem√©tico (21.4107) y un 310.2% m√°s tard√≠o que el *peor* resultado de la optimizaci√≥n de colonia de hormigas (11.64).

- **Seg√∫n el tiempo promedio de ejecuci√≥n**
    - **Para n=20:** La b√∫squeda dispersa se posiciona como el algoritmo m√°s r√°pido de las 3 metaheur√≠sticas, con 3 de sus soluciones posicion√°ndose en las 5 respuestas m√°s r√°pidas y con todas sus soluciones entranado en el top 10. Con excepci√≥n del caso ACO6, el algoritmo mem√©tico supera en velocidad a la optimizaci√≥n de colonia de hormigas en todas sus respuestas, dejando a la optimizaci√≥n de colonia de hormigas como el algorimto m√°s tard√≠o en l√≠neas generales. 
        
    - **Para n=25:** La b√∫squeda dispersa se posiciona nuevamente como el algoritmo m√°s r√°pido de los 3, teniendo en esta ocaci√≥n 4 de las 5 soluciones m√°s r√°pidas registradas. En esta ocasi√≥n las diferencias de velocidad entre el algorimto mem√©tico y la optimizaci√≥n de colonia de hormigas son mucho m√°s difusas, siendo complicado establecer con certeza el predominio de una metaheur√≠stica sobre la otra. 

## üìö Referencias

1. [C. Ting, C. Su and C. Lee. Multi-parent extension of partially mapped crossover for combinatorial optimization problems. Expert Systems with Applications 37, p. 1879‚Äì1886, 2010.](https://mx.nthu.edu.tw/~ckting/pubs/eswa2010.pdf)
2. [Mart√≠, R. Laguna, M. Glover F. Principles of Scatter Search. Dpto. de Estad√≠stica e Investigaci√≥n Operativa, Facultad de Matem√°ticas, Universidad de Valencia, 2003](https://www.uv.es/rmarti/paper/docs/ss8.pdf)
