# CI5652 - Identical Machine Scheduling
Proyecto de Dise√±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad Sim√≥n Bol√≠var.

## üìù Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ü§î Descripci√≥n del problema
Dado un conjunto de `n` tareas y `m` m√°quinas id√©nticas, el objetivo es asignar cada tarea a una m√°quina y determinar la secuencia de tareas en cada m√°quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaci√≥n del trabajo `j`.

# üìã INFORME DEL PROYECTO - PRIMER CORTE
El programa est√° implementado en C++ y consta de los siguientes archivos:

- `exact.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n exacta para el problema.
- `heuristic.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una heur√≠stica para el problema.
- `vicinities.cpp`: Archivo del programa que contiene la implementaci√≥n de la estructura de vecindad para el problema.
- `local_search.cpp`: Archivo principal del programa que contiene la implementaci√≥n de la b√∫squeda local para el problema.
- `Job.h`: Archivo de encabezado que define la estructura `Job`.
- `utilities.h`: Archivo de encabezado que contiene funciones utilitarias para leer archivos de entrada y manipulaci√≥n de cadenas.

üìÇ En la carpeta `benchmarks` se encuentran los casos de pruebas que se utilizaran para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## üëå Implementaci√≥n de una soluci√≥n exacta para el problema
El algoritmo exacto para el problema de Identical Machine Scheduling es un algoritmo de fuerza bruta que genera todas las permutaciones posibles de las tareas y calcula la tardanza total para cada permutaci√≥n. El algoritmo selecciona la permutaci√≥n que minimiza la tardanza total y devuelve la secuencia de tareas correspondiente.

Este algoritmo utiliza backtracking + bitmask para encontrar la soluci√≥n exacta al problema de programaci√≥n de trabajos en m√°quinas id√©nticas. El objetivo es minimizar la tardanza total.

El algoritmo propuesto toma una lista de trabajos, la distribuci√≥n de trabajos por cada m√°quina y una m√°scara que representa los trabajos que ya han sido asignados. La m√°scara es un n√∫mero binario donde cada bit representa si un trabajo ha sido asignado o no.

El algoritmo de backtracking funciona de la siguiente manera:

Si todos los trabajos han sido asignados (es decir, la m√°scara es igual a `(1 << jobs.size()-1)`), entonces devuelve la distribuci√≥n de trabajos por cada m√°quina.

De lo contrario, para cada trabajo que a√∫n no ha sido asignado (es decir, `!(mask & (1 << i))` es verdadero), intenta asignarlo a cada programaci√≥n y realiza una llamada recursiva a la misma funci√≥n con el trabajo asignado.

Despu√©s de cada llamada recursiva, compara la tardanza total de la soluci√≥n actual con la tardanza total de la mejor soluci√≥n encontrada hasta ahora. Si la soluci√≥n actual es mejor, entonces la guarda como la mejor soluci√≥n.

Finalmente, despu√©s de haber probado todas las asignaciones posibles, devuelve la mejor soluci√≥n encontrada.

Este algoritmo garantiza encontrar la soluci√≥n √≥ptima porque genera y verifica todas las asignaciones posibles de trabajos a las maquinas. Sin embargo, su tiempo de ejecuci√≥n es exponencial en el n√∫mero de trabajos, por lo que solo es pr√°ctico para problemas de tama√±o peque√±o.

#### Tiempo de complejidad:
Este algoritmo toma un tiempo de complejidad  $`O(m*n*m^n) = O(n*m^{n+1})`$ ya que se considera las posibles combinaciones de repartir las n tareas entre las m m√°quinas (cada tarea se tiene m elecciones) y adem√°s en cada posible combinaci√≥n se calcula la tardanza total, que toma tiempo $`O(n*m)`$. 

## üß† Implementaci√≥n de una heur√≠stica para el problema
El algoritmo MDD (Modified Due Date) es un enfoque heur√≠stico creada en 1982 por Baker y Bertrand,  utilizada para resolver el problema de tardanza ponderada total de una sola m√°quina. M√°s tarde, en 1997,  Alidaee y Rosa extendieron este algoritmo MDD para el caso de m√°quinas paralelas como se describe a continuaci√≥n:

1. Se tiene una lista de tareas no programadas `U`.
2. Para cada m√°quina `j`, dividir `U` en dos subconjuntos `U1j` y `U2j` para `j` = 1, 2, ..., `m`.
    > `U1j` contiene las tareas que no se pueden completar en su fecha de vencimiento en la m√°quina `j`.

    > `U2j` contiene las tareas que s√≠ se pueden completar antes de su fecha de vencimiento en la m√°quina `j`.
3. De `U1j` y `U2j`, encontrar los subconjuntos `Œ≥j` y `Œªj` que contienen las tareas con el tiempo de procesamiento m√≠nimo y la fecha de vencimiento m√≠nima, respectivamente.
4. Seleccionar una tarea `gj` de `Œ≥j` o `Œªj` que minimice el valor de MDD en la m√°quina `j`. El valor de MDD en la m√°quina `j` de una tarea `i` est√° dada por `MDD = max(Cj + pi, di)` 
    > `Cj` es la suma del procesamiento de tiempo de las tareas que ya han sido programados en la m√°quina `j`.

    > `pi` es el tiempo de procesamiento de la tarea `i` con su fecha de vencimiento `di`.
5. Programar la tarea `gl` en la m√°quina `l` que produzca el valor MDD m√≠nimo. 
6. Eliminar la tarea `gl` de la lista `U` de trabajos no programados.
7. Repetir los pasos 2-6 hasta que no queden trabajos por programar.

#### Tiempo de complejidad:
1. Particionar U en dos subconjuntos toma $`O(n)`$ (en el peor caso, tenemos n tareas sin programar).
2. Encontrar los subconjuntos `Œ≥j` y `Œªj` tambi√©n toma $`O(n)`$.
3. Luego, buscar la tarea `gj` para una m√°quina `j` tambi√©n toma $`O(n)`$.
4. Y encontrar la tarea `gl` de todas las m√°quinas y de las tareas sin programar con el valor m√≠nimo de MDD toma $`O(m*n)`$.
5. Y finalmente, como tenemos que escoger una tarea `gl` y eliminarla del conjunto de tareas no programadas en cada paso, el algoritmo MDD completo tarda es $`O(n^2*m)`$.

## üèòÔ∏è Definici√≥n de una estructura de vecindad e implementaci√≥n de la b√∫squeda local para el problema

Tras ser implementada las versiones heur√≠stica y exacta de la soluci√≥n el problema se procedi√≥ a efectuar la implementaci√≥n de la metaheur√≠stica de b√∫squeda local para obtener soluciones aproximadas y medir su desempe√±o en contraste a las otras dos soluciones prove√≠das.

El aspecto fundamental de la metaheur√≠stica de b√∫squeda local radica en la selecci√≥n de las estructuras de vecindad para el problema a resolver. Para el caso de IMS se opt√≥ por una estructura de vecindad que gira alrededor de 6 modificaciones b√°sicas que se le pueden efectuar a cualquier estado dado de la soluci√≥n del problema:

- **Shift**: Un vecino en la vecindad *Shift* es generado re-agendando un trabajo de la m√°quina objetivo `m_x` en alguna posici√≥n aleatoria dentro de la misma m√°quina.
- **Switch**: Un vecino en la vecindad *Switch* es generado intercambiando las posiciones de dos trabajos aleatoriamente seleccionados dentro de la m√°quina objetivo.
- **Task Move**: Un vecino en la vecindad *Task Move* es generado escogiendo aleatoriamente un trabajo dentro de la m√°quina objetivo `m_x` y re-agend√°ndolo aleatoriamente en una segunda m√°quina, `m_y`, seleccionada al azar.
- **Swap**: Un vecino en la vecindad *Swap* es generado intercambiando dos trabajos aleatoriamente seleccionados entre dos m√°quinas: la m√°quina objetivo `m_x`, y otra m√°quina elegida al azar, `m_y`. Los trabajos transferidos son insertados en posiciones aleatorias dentro de cada m√°quina correspondiente.
- **Two-Shift**: Un vecino en la vecindad *Two-Shift* es generado cambiando aleatoriamente la posici√≥n de dos trabajos dentro de la m√°quina objetivo `m_x`. Efectivamente, es equivalente a dos aplicaciones consecutivas de la vecindad *Shift*.
- **Direct-Swap**: Un vecino en la vecindad *Direct-Swap* es generado intercambiando dos trabajos entre dos m√°quinas `m_x` y `m_y`, respetando la posici√≥n que ten√≠a el trabajo contrario dentro del cronograma de su m√°quina correspondiente antes de ser removido (Si los trabajos son `j_x` y `j_y`, `j_x` ser√° insertado en `m_y` en la misma posici√≥n que ten√≠a `j_y` antes de ser removido, y viceversa).

De esta manera la generaci√≥n de un vecino a partir de un estado de la soluci√≥n consiste en la selecci√≥n aleatoria y posterior ejecuci√≥n de alguna de estas 6 operaciones sobre la m√°quina que m√°s tardanza est√© contribuyendo a la soluci√≥n (En el caso de las vecindades que involucran dos m√°quinas, una ser√° la m√°quina m√°s tard√≠a y la otra ser√° seleccionada aleatoriamente). Como puede intuirse, la inclusi√≥n de varias estructuras de vecindad distintas traen como consecuencia una explosi√≥n en tama√±o del conjunto de vecindades de cualquier estado dado, adem√°s, al ser la selecci√≥n de vecindades realizada de manera aleatoria, termina siendo complicado estructurar mecanismos que permitan explorar la vecindad de un estado de manera ordenada eficientemente. Por estos motivos el algoritmo de b√∫squeda local implementado no garantiza el agotamiento de todos los vecinos de un estado antes de culminar su ejecuci√≥n, optando m√°s bien por la definici√≥n de un n√∫mero m√°ximo de iteraciones en las que *no se presente una mejora en el resultado* (Esto es, en caso de encontrar una mejor soluci√≥n, se toma la nueva soluci√≥n candiadata y el contador de iteraciones vuelve a 0). Para la ejecuci√≥n de los *benchmarks* el n√∫mero m√°ximo de iteraciones permitidas al programa se defini√≥ en 65,000. La elecci√≥n de este n√∫mero fue tomada emp√≠ricamente tras experimentar con distintos valores, con 65,000 iteraciones presentando un razonable punto medio entre calidad de resultados y tiempo razonable de ejecuci√≥n.

El algoritmo de b√∫squeda local implementado no hace uso de pol√≠ticas de intensificaci√≥n ni diversificaci√≥n. Adem√°s, no se opt√≥ por implementar b√∫squeda guiada, tab√∫ u otras variaciones de la meta-heur√≠stica b√°sica de B√∫squeda Local.

## üöÄ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./LocalSearch <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el n√∫mero del algoritmo a ejecutar:

1. Heur√≠stica
2. B√∫squeda Local
3. Algoritmo Exacto

## üìÑ Analisis de resultados

A continuaci√≥n se presenta el an√°lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomar√° en cuenta los valores de tardanza √≥ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados.


### üìä M√©tricas Comparativas

Las m√©tricas claves en el an√°lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la Soluci√≥n √ìptima (Optimal Solution Difference)**: La diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima.

### üìà Resultados

Los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` se encuentran en el directorio `results`, sin embargo, debido a la cantidad de datos obtenidos, se almacen√≥ los datos m√°s relevantes en el siguiente enlace: [Resultados](https://docs.google.com/spreadsheets/d/1nE2hubPLtpBfe2wIpuzA0SgOXGMpi-NJaMEHRL38QYM/edit?usp=sharing)

A modo de resumen y para facilitar la visualizaci√≥n de los resultados, se presentan las tablas comparativas resumidas a continuaci√≥n:

|   n  |  m  | Promedio de diferencia de tardanza para el algoritmo heuristica  vs la tardanza √≥ptima | Promedio de diferencia de tardanza para el algoritmo ls con soluci√≥n inicial heuristica  vs la tardanza √≥ptima | Promedio de diferencia de tardanza para el algoritmo ls  con soluci√≥n inicial aleatoria  vs la tardanza √≥ptima  |
|:----:|:---:|:-----------:|:-------------------:|:-----------------:|
|  20  |  2  |    14,784   |        6,32         |       36,42       |
|  20  |  3  |    18,544   |        9,2          |       62,184      |
|  20  |  4  |    20,936   |        10,704       |       115,04      |
|  20  |  5  |    21,512   |        11,92        |       105,824     |
|  20  |  6  |     20,6    |        10,256       |       122,864     |
|  20  |  7  |    20,688   |        11,744       |      143,536      |
|  20  |  8  |    20,016   |        10,8         |      153,896      |
|  20  |  9  |    17,944   |        8,904        |      148,736      |
|  20  | 10  |    16,176   |        8,992        |      166,864      |
|  25  |  2  |     25,88   |        10,464       |      27,624       |
|  25  |  3  |    23,176   |        12,416       |      52,584       |
|  25  |  4  |    22,064   |        13,056       |      63,36        |
|  25  |  5  |    23,528   |        11,92        |      88,68        |
|  25  |  6  |    23,024   |        10,256       |      114,272      |
|  25  |  7  |    22,656   |        11,744       |      122,384      |
|  25  |  8  |    21,528   |        10,8         |      137,136      |
|  25  |  9  |    21,416   |        8,904        |      148,912      |
|  25  | 10  |    22,896   |        8,992        |      149,896      |

|   n  |  m  | Promedio de tiempo para el algoritmo heuristica (s) | Promedio de tiempo para el algoritmo ls con soluci√≥n inicial heuristica (s) | Promedio de tiempo para el algoritmo ls con soluci√≥n inicial aleatoria (s) |
|:----:|:---:|:---------------------------------------------------------------:|:-------------------------------------------------------------------:|:----------------------------------------------------------------:|
|20 |	2	|0,000177437608|	0,5536462978|	0,684012973|
|20 |	3	|0,000250604512|	0,6705884606|	0,8120744103|
|20	|   4	|0,000177437608|	0,8305885517|	0,9842081426|
|20	|   5	|0,000421948168|	0,9994120584|	1,10762457|
|20	|   6	|0,000490450608|	1,181125517|	1,279287094|
|20	|   7	|0,000561551|	    1,354315666|	1,43728576|
|20	|   8	|0,000332425656|	1,55716976|	    1,62052424|
|20	|   9	|0,00034788928|	    1,72209336|	    1,76874936|
|20	|   10	|0,000428774128|	1,90492776|	    2,00072456|
|25	|   2	|0,000115114784|	0,6300726939|	0,8729056595|
|25	|   3	|0,000178468432|	0,8133722274|	1,109488589|
|25	|   4	|0,000224764072|	0,9550425673|	1,236124276|
|25	|   5	|0,000285201784|	1,114882156|	1,405418945|
|25	|   6	|0,000326256624|	1,297659981|	1,403675999|
|25	|   7	|0,000390043864|	1,299856236|	1,470842934|
|25	|   8	|0,000449967848|	1,369663928|	1,556300776|
|25	|   9	|0,000483178408|	1,325604456|	1,560743072|
|25	|   10	|0,000521611536|	1,373501304|	1,414723992|

- **Algoritmo Exacto**: En el caso del algoritmo exacto propuesto, el tiempo de ejecuci√≥n para el benchmark propuesto result√≥ ser excepcionalmente alto. A pesar de haberse ejecutado el algoritmo durante m√°s de una hora, no se logr√≥ obtener una soluci√≥n. Por consiguiente, se tom√≥ la decisi√≥n de no incorporar estos resultados en la tabla comparativa. La raz√≥n de este comportamiento radica en la complejidad exponencial del algoritmo exacto, lo que lo hace inviable para instancias de gran tama√±o. No obstante, se anticipa que este algoritmo pueda proporcionar la soluci√≥n √≥ptima para los casos de prueba.

- **Algoritmo Heur√≠stico**: El algoritmo heur√≠stico propuesto logr√≥ obtener resultados aceptables en comparaci√≥n con la soluci√≥n √≥ptima. En promedio, la diferencia de tardanza fue de 19,02 para instancias de tama√±o 20 y 22,91 para instancias de tama√±o 25. En cuanto al tiempo de ejecuci√≥n, el algoritmo heur√≠stico se ejecut√≥ en un tiempo promedio de 0,0004 segundos para instancias de tama√±o 20 y 0,0004 segundos para instancias de tama√±o 25. En general, el algoritmo heur√≠stico demostr√≥ ser eficiente y efectivo para instancias de tama√±o moderado. 

    A partir de los resultados obtenidos, se puede concluir que el algoritmo heur√≠stico propuesto es una soluci√≥n viable para instancias de tama√±o moderado. A pesar de no garantizar la soluci√≥n √≥ptima, el algoritmo heur√≠stico logra obtener resultados aceptables en un tiempo de ejecuci√≥n razonable. Por otro lado, el algoritmo exacto se muestra como una alternativa para instancias de tama√±o peque√±o, aunque su complejidad exponencial lo hace inviable para instancias de gran tama√±o.

- **Algoritmo de B√∫squeda Local con Soluci√≥n Inicial de la Heur√≠stica**: El algoritmo de b√∫squeda local con heur√≠stica logr√≥ obtener resultados superiores en comparaci√≥n con el algoritmo heur√≠stico. En promedio, la diferencia de tardanza fue de 9,87 para instancias de tama√±o 20 y 10,95 para instancias de tama√±o 25. En cuanto al tiempo de ejecuci√≥n, el algoritmo de b√∫squeda local con heur√≠stica se ejecut√≥ en un tiempo promedio de 1,35 segundos para instancias de tama√±o 20 y 1,22 segundos para instancias de tama√±o 25. En general, observamos que el algoritmo de b√∫squeda local con heur√≠stica logra mejorar la soluci√≥n obtenida por el algoritmo heur√≠stico en gran medida, aunque a costa de un mayor tiempo de ejecuci√≥n, sin embargo, el tiempo de ejecuci√≥n sigue siendo razonable si tomamos en cuenta el porcentaje de mejora en la tardanza total, para el caso de 20 tareas es de 48,11% y para el caso de 25 tareas es de 52.20%, lo que nos indica que el algoritmo de b√∫squeda local con heur√≠stica es una muy buena opci√≥n si se busca una mejor aproximaci√≥n a la soluci√≥n √≥ptima.

- **Algoritmo de B√∫squeda Local con Soluci√≥n Inicial Aleatoria**: El algoritmo de b√∫squeda local con soluci√≥n inicial aleatoria logr√≥ obtener resultados bastante m√°s
bajos en comparaci√≥n con el algoritmo de b√∫squeda local con heur√≠stica. En promedio, la diferencia de tardanza fue de 117,26 para instancias de tama√±o 20 y 100,54 para instancias de tama√±o 25. En cuanto al tiempo de ejecuci√≥n, el algoritmo de b√∫squeda local con soluci√≥n inicial aleatoria se ejecut√≥ en un tiempo promedio de 1,38 segundos para instancias de tama√±o 20 y 1,34 segundos para instancias de tama√±o 25. En general, observamos que el algoritmo de b√∫squeda local con soluci√≥n inicial aleatoria no logra mejorar la soluci√≥n obtenida por el algoritmo heur√≠stico. 

    La raz√≥n de este comportamiento radica en la calidad de la soluci√≥n inicial. Al utilizar una soluci√≥n inicial aleatoria, el algoritmo de b√∫squeda local se enfrenta a un espacio de b√∫squeda que en promedio llevar√° a cuencas de atracci√≥n que no son favorables, lo que dificulta la convergencia hacia una soluci√≥n √≥ptima. Por otro lado, el algoritmo de b√∫squeda local con heur√≠stica logra obtener una soluci√≥n inicial de mayor calidad, lo que facilita la convergencia hacia una soluci√≥n √≥ptima. En general, se observa que la calidad de la soluci√≥n inicial juega un papel crucial en el rendimiento del algoritmo de b√∫squeda local.

## üìå Conclusiones

En este proyecto, se ha abordado el problema de Identical Machine Scheduling, el cual consiste en asignar un conjunto de tareas a un conjunto de m√°quinas id√©nticas de manera que se minimice la tardanza total. Para resolver este problema, se han implementado diferentes algoritmos, incluyendo un algoritmo exacto, un algoritmo heur√≠stico y un algoritmo de b√∫squeda local. 

Para el caso del algoritmo exacto, se observ√≥ que su complejidad exponencial lo hace inviable para instancias de gran tama√±o, como es el caso de los benchmarks propuestos. A pesar de no haber obtenido una soluci√≥n en un tiempo razonable, se anticipa que el algoritmo exacto pueda proporcionar la soluci√≥n √≥ptima para instancias de tama√±o peque√±o. 

Por otra parte, el an√°lisis derivado de los resultados obtenidos con el algoritmo heur√≠stico, el algoritmo de b√∫squeda local con soluci√≥n inicial de la heur√≠stica y el algoritmo de b√∫squeda local con soluci√≥n inicial aleatoria, permiti√≥ concluir que el algoritmo de b√∫squeda local con soluci√≥n inicial de la heur√≠stica es la mejor opci√≥n para obtener una soluci√≥n aproximada al problema de Identical Machine Scheduling. A pesar de que el algoritmo de b√∫squeda local con soluci√≥n inicial aleatoria no logr√≥ mejorar la soluci√≥n obtenida por el algoritmo heur√≠stico, se observ√≥ que la calidad de la soluci√≥n inicial juega un papel crucial en el rendimiento del algoritmo de b√∫squeda local.

## üìö Referencias

1. [S. Tanaka and M. Araki. A branch-and-bound algorithm with Lagrangian relaxation to minimize total tardiness on identical parallel machines. International Journal of Production Economics 113(5), p. 446-458, 2008. ](https://www.sciencedirect.com/science/article/abs/pii/S0925527307003027?via%3Dihub)

2. [S. Tanaka and M. Araki. Benchmark for Identical Parallel Machine Scheduling with Total Tardiness](https://sites.google.com/site/shunjitanaka/pmtt)

3. [H. Santos, T. Toffolo, C. Silva and G. Vanden Berghe. Analysis of stochastic local search methods for the unrelated
parallel machine scheduling problem. Intl. Trans. in Op. Res. 00 (2016) 1‚Äì18](http://www.decom.ufop.br/haroldo/papers/Santos2019.pdf)
