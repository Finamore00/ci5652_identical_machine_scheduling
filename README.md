# CI5652 - Identical Machine Scheduling
Proyecto de Dise√±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad Sim√≥n Bol√≠var.

## üìù Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ü§î Descripci√≥n del problema
Dado un conjunto de `n` tareas y `m` m√°quinas id√©nticas, el objetivo es asignar cada tarea a una m√°quina y determinar la secuencia de tareas en cada m√°quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaci√≥n del trabajo `j`.

# üìã INFORME DEL PROYECTO - SEGUNDO CORTE
El programa est√° implementado en C++ y consta de los siguientes archivos para este tercer corte:

- `memetic.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo mem√©tico para el problema.
- `aco.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo de optimicaci√≥n de colonia de hormigas para el problema.

üìÇ En la carpeta `benchmarks` se encuentran los casos de pruebas de la primera corte del proyecto para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## Definici√≥n del operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres, el m√©todo de mejora luego de la recombinaci√≥n y la implementaci√≥n del algoritmo mem√©tico

### ( Õ°¬∞ Õú ñ Õ°¬∞) Algoritmo Mem√©tico üòÇ

### Operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres

- **Operador de cruce utilizado en el algoritmo gen√©tico**: Cruce parcialmente mapeado.

- **Cruce parcialmente mapeado para m√∫ltiples padres**: Se implementa el cruce parcialmente mapeado para m√∫ltiples padres, cuyo proceso consiste en:

    1. Sea `k` el n√∫mero de padres. 

    2. Se seleccionan aleatoriamente `k` puntos de corte para dividir cada padre en `k + 1` subpartes.

    ![Ejemplo de subpartes](./img/ejemplo_subpartes.png)

    3. Se crea una lista de mapeo (`ch_map`) utilizando la funci√≥n `create_mapping_list`. Esta lista mapea los genes (o tareas) de diferentes padres entre s√≠. 

        3.1. Sea `g` el n√∫mero de genes o tareas de un individuo.

        3.2. Se crea un arreglo `job_mapped` para rastrear qu√© tareas ya han sido mapeados y un contador de tareas mapeados `cnt_mapped`

        3.3. Se selecciona aleatoriamente un padre `start_parent` y un gen inicial del padre seleccionado `start_gene`.

        3.4. Luego se ejecuta un bucle con `g` iteraciones
        
            3.4.1. En el bucle, se marca el gen actual `start_gene` como mapeado.

            3.4.2. Se selecciona un padre final `end_parent` aleatoriamente y diferente del padre inicial y se busca en el padre final el gen que corresponde a la misma tarea que el gen inicial, al encontrarlo se guarda el gen en `end_gene`.

            3.4.3. Se incrementa `cnt_mapped` a 1. Si todos las tareas han sido mapeados, se sale del bucle.

            3.4.4. Si a√∫n faltan tareas por mapear, se elige un nuevo padre inicial diferente del final y se selecciona un nuevo gen inicial cuya tarea no haya sido mapeada a√∫n.

            3.4.5. Y se agrega un mapeo con `ch_map[end_gene.job->id] = start_gene`

        3.5. Despu√©s del bucle, se agrega un mapeo final de la tarea del √∫ltimo gen a la tarea del gen inicial (el primer gen que se mapea). Esto para crear un mapeo c√≠clico entre tareas.

        ![Mapeo de genes](./img/mapeo_genes.png)

    4. Luego, se crea un orden aleatorio en los genes para cada subparte con la funci√≥n `create_random_order` y este orden aleatorio se guarda en un arreglo `order`

    5. Se crean los `k` hijos.

    6. Primero cada hijo `i` se copia la primera subparte del padre `i` (antes del primer punto de corte y despu√©s del √∫ltimo punto de corte).

    7. Luego, para cada hijo `i`, las subpartes entre los puntos de corte se copian de otros padres en un patr√≥n diagonal.

    8. Posteriormente, se legaliza cada hijo para asegurar que no hayan trabajos duplicados.

        8.1. Se crea un nuevo orden aleatorio `new_order` para procesar las subpartes del hijo `i`.

        8.2. Se marcan inicialmente la primera subparte procesada, o sea, la primera subparte de cada hijo permanece igual.

        8.3. Para cada subparte restante seg√∫n el orden en `new_order`.

            8.3.1. Se revisa cada gen de la subparte actual seg√∫n el orden en `order`.

            8.3.2. Si la tarea ya est√° marcado (duplicado), se reemplaza con el trabajo mapeado seg√∫n la lista de mapeo (`ch_map`). Este proceso contin√∫a hasta encontrar un trabajo no marcado.
            
            8.3.3. Al encontrar un trabajo no marcado, se marca el nuevo trabajo y se actualiza el gen en el hijo actual.

        8.4. Se verifica que todas las tareas est√©n marcadas (para asegurar que no hayan tareas duplicadas y tampoco tareas faltantes).

    9. Se devuelven los hijos generados.

### Mejora luego de la recombinaci√≥n

Para este paso, se utiliza la b√∫squeda local implementada en la primera corte del proyecto.

1. Sea un hijo `h` producido en la recombinaci√≥n.

2. Se decodifica el genotipo del hijo `h` en un fenotipo v√°lido.

3. Luego, se le aplica la b√∫squeda local al fenotipo convertido.

4. Y por √∫ltimo, el resultado de la b√∫squeda local se transforma nuavemente en un genotipo.

### Par√°metros del algoritmo mem√©tico

Aparte de recibir las tareas y la cantidad de m√°quinas, y los par√°metros del algoritmo gen√©tico: 
- population_size: El tama√±o de la poblaci√≥n

- mutation_rate: El porcentaje de mutaci√≥n.

- max_iter: El m√°ximo n√∫mero de iteraciones o generaciones.

El algoritmo mem√©tico recibe adicionalmente los siguientes par√°metros:
- nro_parents_crossover: Un entero para la cantidad de padres para ser seleccionadas para la recombinaci√≥n en cada generaci√≥n.

- opt_freq: Un entero que indica la frequencia de aplicar la mejora con la b√∫squeda local. Responde a la pregunta de ¬øcada cu√°ntas generaciones se lanza la optimizaci√≥n?

- opt_rate: Un float para el porcentaje de aplicar la mejora en la b√∫squeda local sobre los descendientes. ¬øCu√°ntos invididuos generados son optimizados en cada generaci√≥n?

- random_opt_rate: Un valor booleano que indica si aplicar la b√∫squeda local con un porcentaje aleatorio en  cada generaci√≥n o aplicarlo seg√∫n el opt_rate. Y si es aleatorio, el valor del par√°metro es true, en caso contrario es false. Adem√°s, si es aleatorio, el valor de porcentaje para la b√∫squeda local en cada generaci√≥n debe ser mayor que 10%, esto para asegurar que siempre se aplique una cantidad significativa de optimizaci√≥n local.

## Definici√≥n del comportamiento de la feromona/heur√≠stica e implemente con ello una optimizaci√≥n de colonia de hormigas
### üêú Optimizaci√≥n de Colonia de Hormigas

#### Feromona 

- **Estructura**: Se implementa como una matriz bidimensional donde cada elemento œÑ[i][j] representa el nivel de feromona para asignar la tarea i a la m√°quina j.

- **Inicializaci√≥n**: Al comenzar, todos los valores de feromona se establecen en 1.0, indicando que inicialmente no hay preferencia por ninguna asignaci√≥n.

- **Actualizaci√≥n local**: Despu√©s de cada asignaci√≥n de tarea, se actualiza la feromona usando la f√≥rmula:
  œÑ[job][machine] = (1 - œÅ_local) * œÑ[job][machine] + œÅ_local * ŒîœÑ
  Donde ŒîœÑ es 1 dividido por el retraso m√°ximo calculado inicialmente y œÅ_local es un par√°metro que controla la tasa de evaporaci√≥n local.

- **Actualizaci√≥n global**: Al final de cada iteraci√≥n, se actualiza la feromona bas√°ndose en la mejor soluci√≥n encontrada:
  œÑ[i][j] = (1 - œÅ_global) * œÑ[i][j] + œÅ_global * (1 / mejor_retraso) 
    Donde œÅ_global es un par√°metro que controla la tasa de evaporaci√≥n global y mejor_retraso es el retraso total de la mejor soluci√≥n encontrada.

- **Uso**: En la selecci√≥n de tareas, la feromona se eleva a la potencia Œ± para ajustar su influencia en la decisi√≥n.

#### Heur√≠stica


- **C√°lculo**: Se define como el inverso del retraso modificado de la fecha de vencimiento (modified due date tardiness o MDD):
  Œ∑ = 1 / MDD(tiempo_actual_m√°quina, tarea)

- **Funci√≥n MDD**: Calcula el retraso potencial de una tarea si se asignara a una m√°quina en un momento dado. 

- **Uso**: En la selecci√≥n de tareas, la heur√≠stica se eleva a la potencia Œ≤ para ajustar su influencia en la decisi√≥n.

- **Equilibrio con la feromona**: La probabilidad de seleccionar una tarea para una m√°quina se calcula como:
  P[i][j] ‚àù (œÑ[i][j])^Œ± * (Œ∑[i][j])^Œ≤
  Donde œÑ es la feromona, Œ∑ es la heur√≠stica, y Œ± y Œ≤ son par√°metros que controlan la importancia relativa de la feromona y la heur√≠stica respectivamente.

Esta combinaci√≥n de feromona y heur√≠stica permite al algoritmo equilibrar entre explotar la informaci√≥n aprendida (a trav√©s de la feromona) y responder a las caracter√≠sticas espec√≠ficas de cada tarea y el estado actual de las m√°quinas (a trav√©s de la heur√≠stica). Esto gu√≠a al algoritmo hacia soluciones que minimizan el retraso total de las tareas, adapt√°ndose din√°micamente a medida que construye y mejora las soluciones.

#### Pasos del Algoritmo

1. **Inicializaci√≥n**

El algoritmo comienza creando la matriz de feromonas. Adem√°s, se calcula el MDD Tardiness que se usa como referencia para la actualizaci√≥n local de la feromona. 

2. **Ciclo principal**

El coraz√≥n del algoritmo es un ciclo que se repite un n√∫mero fijo de veces. Cada repetici√≥n de este ciclo representa una generaci√≥n completa de soluciones. Durante cada iteraci√≥n, el algoritmo generar√° una soluci√≥n, la mejorar√°, y usar√° la informaci√≥n obtenida para influir en las siguientes generaciones.

3. **Construcci√≥n de soluciones**

En esta fase, el algoritmo crea m√∫ltiples soluciones desde cero. Cada soluci√≥n se construye de manera similar a c√≥mo una hormiga construir√≠a un camino. Se comienza con todas las tareas sin asignar y todas las m√°quinas vac√≠as. Luego, para cada tarea, se selecciona primero una m√°quina, favoreciendo aquellas con menos tiempo de procesamiento acumulado. Despu√©s, se elige una tarea para esa m√°quina, bas√°ndose en los niveles de feromona (que indican qu√© tan buena ha sido esta asignaci√≥n en el pasado) y la urgencia de la tarea. Una vez hecha la asignaci√≥n, se actualiza el tiempo de procesamiento de la m√°quina y se modifica ligeramente el nivel de feromona para esa combinaci√≥n espec√≠fica de tarea y m√°quina.

4. **Actualizaci√≥n local de feromonas**

Despu√©s de asignar cada tarea a una m√°quina, el algoritmo actualiza los niveles de feromona localmente. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que se han asignado en esta soluci√≥n.

5. **Mejora local**

Una vez construida una soluci√≥n completa, el algoritmo intenta mejorarla. Esto se hace mediante un proceso de b√∫squeda local.

6. **Evaluaci√≥n**

Despu√©s de mejorar cada soluci√≥n, el algoritmo calcula su calidad midiendo el retraso total que produce. Si esta soluci√≥n resulta ser mejor que la mejor encontrada hasta ahora (es decir, si produce un retraso total menor), se guarda como la nueva mejor soluci√≥n. 

7. **Actualizaci√≥n global de feromonas**

Al final de cada iteraci√≥n, despu√©s de haber construido y evaluado todas las soluciones de esa generaci√≥n, el algoritmo actualiza la matriz de feromonas bas√°ndose en la mejor soluci√≥n encontrada. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que aparecen en la mejor soluci√≥n.

8. **Evaporaci√≥n de feromonas**

Para evitar que el algoritmo se quede atrapado en soluciones sub√≥ptimas, se implementa un mecanismo de evaporaci√≥n de feromonas. Esto significa que en cada iteraci√≥n, todos los niveles de feromona se reducen ligeramente.

9. **Finalizaci√≥n**

Despu√©s de completar todas las iteraciones programadas, el algoritmo termina y devuelve la mejor soluci√≥n que ha encontrado. Esta soluci√≥n representa la programaci√≥n de tareas que, seg√∫n el algoritmo, deber√≠a producir el menor retraso total posible dado el conjunto de tareas y m√°quinas disponibles.


## Definici√≥n de reglas para movimientos que han de ser tab√∫s e implementaci√≥n de una b√∫squeda tab√∫.

### üö´ Tabu Search

La implementaci√≥n del algoritmo de B√∫squeda Tab√∫ recibe la informaci√≥n de las `n` tareas, la cantidad de `m` m√°quinas, y varios par√°metros que controlan el proceso de b√∫squeda, como el n√∫mero m√°ximo de iteraciones y la tenencia de la lista tab√∫. A continuaci√≥n se describen los pasos de la implementaci√≥n:

1. **Inicializaci√≥n:** 
    - El algoritmo empieza creando una soluci√≥n inicial `S` utilizando el m√©todo `mddScheduling`. 
    - Esta soluci√≥n `S` es considerada la mejor soluci√≥n conocida hasta el momento (`best_schedule`).

2. **Lista Tab√∫:** 
    - Se inicializa una lista tab√∫ para almacenar los movimientos que est√°n prohibidos temporalmente.

3. **Iteraciones principales:** 
    - Para cada iteraci√≥n, se identifica la m√°quina con mayor tardanza (`tardiest_machine`).
    - Se generan m√∫ltiples vecinos de la soluci√≥n actual mediante movimientos aleatorios en la m√°quina con mayor tardanza.
    - Se selecciona el mejor vecino que no est√© en la lista tab√∫ o que mejora la mejor soluci√≥n conocida.

4. **Actualizaci√≥n de la lista Tab√∫:** 
    - Si el mejor vecino no est√° en la lista tab√∫ o mejora la mejor soluci√≥n conocida, se actualiza la soluci√≥n actual y se a√±ade uno de los √≠ndices de los trabajos restantes de la maquina con m√°s tardiness a la lista tab√∫, esto para asegurar que no se extraigan varias veces elementos de la misma maquina, evitando as√≠ ciclos.
    - Si la lista tab√∫ excede su tama√±o m√°ximo (`tabu_tenure`), se elimina el movimiento m√°s antiguo.

5. **Actualizaci√≥n de la mejor soluci√≥n:** 
    - Si el vecino seleccionado mejora la mejor soluci√≥n conocida, se actualiza la mejor soluci√≥n.

6. **Repetici√≥n:** 
    - Se repiten los pasos 3-5 hasta que se agoten las iteraciones.

El algoritmo `Tabu Search` busca explorar el espacio de soluciones evitando ciclos y escapando de √≥ptimos locales mediante el uso de una lista tab√∫ que proh√≠be ciertos movimientos temporalmente.

## Definici√≥n de un proceso de enfriado progresivo e implementaci√≥n de un recocido simulado.

### ‚ùÑÔ∏è Simulated Annealing

La implementaci√≥n del algoritmo de Recocido Simulado (Simulated Annealing) recibe la informaci√≥n de las `n` tareas, la cantidad de `m` m√°quinas, y varios par√°metros que controlan el proceso de b√∫squeda, como la temperatura inicial y el factor de reducci√≥n de temperatura. A continuaci√≥n se describen los pasos de la implementaci√≥n:

1. **Inicializaci√≥n:** 
    - El algoritmo empieza creando una soluci√≥n inicial `S` utilizando el m√©todo `mddScheduling`. 
    - Esta soluci√≥n `S` es considerada la mejor soluci√≥n conocida hasta el momento (`best_schedule`).
    - Se inicializa la temperatura `t` con un valor inicial `t0`.

2. **Iteraciones principales:** 
    - Para cada iteraci√≥n, se generan m√∫ltiples vecinos de la soluci√≥n actual mediante movimientos aleatorios.
    - Se calcula la diferencia de tardanza (`delta`) entre el vecino y la soluci√≥n actual.

3. **Criterio de aceptaci√≥n:** 
    - Si el vecino tiene una tardanza menor o igual, se acepta.
    - Si el vecino tiene una tardanza mayor, se acepta con una probabilidad `exp(-delta / t)`.

4. **Actualizaci√≥n de la mejor soluci√≥n:** 
    - Si la soluci√≥n actual mejorada tiene una tardanza menor que la mejor soluci√≥n conocida, se actualiza la mejor soluci√≥n.

5. **Reducci√≥n de la temperatura:** 
    - Despu√©s de un n√∫mero fijo de iteraciones, se reduce la temperatura multiplic√°ndola por un factor `t_step`.
    - Si la temperatura cae por debajo de un umbral `epsilon`, se restablece a su valor inicial `t0`.

6. **Repetici√≥n:** 
    - Se repiten los pasos 2-5 hasta que se agoten las iteraciones.

El algoritmo `Simulated Annealing` busca explorar el espacio de soluciones permitiendo peores soluciones con una probabilidad decreciente, lo que ayuda a escapar de √≥ptimos locales y encontrar mejores soluciones globales.

## üé≤ Definici√≥n de un m√©todo de construci√≥n para una RCL e implementaci√≥n de GRASP.

### üë®‚Äç‚öñÔ∏è M√©todo de construci√≥n para una RCL

Para la definici√≥n del RCL en este problema, se utiliz√≥ el enfoque heur√≠stico Modified Due Date (MDD) explicado en el primer corte del proyecto:

1. Sea `S` una soluci√≥n parcialmente construida.
2. Se tiene una lista de tareas no programadas `U` en la soluci√≥n `S`.
3. Para cada m√°quina `j`, dividir `U` en dos subconjuntos `U1j` y `U2j` para `j` = 1, 2, ..., `m`.
    > `U1j` contiene las tareas que no se pueden completar en su fecha de vencimiento en la m√°quina `j`.

    > `U2j` contiene las tareas que s√≠ se pueden completar antes de su fecha de vencimiento en la m√°quina `j`.
4. De `U1j` y `U2j`, encontrar los subconjuntos `Œ≥j` y `Œªj` que contienen las tareas con el tiempo de procesamiento m√≠nimo y la fecha de vencimiento m√≠nima, respectivamente. 
5. Seleccionar una tarea `gj` de `Œ≥j` o `Œªj` que minimice el valor de MDD en la m√°quina `j`. El valor de MDD en la m√°quina `j` de una tarea `i` est√° dada por `MDD(j, i) = max(Cj + pi, di)` 
    > `Cj` es la suma del procesamiento de tiempo de las tareas que ya han sido programados en la m√°quina `j`.

    > `pi` es el tiempo de procesamiento de la tarea `i` con su fecha de vencimiento `di`.
6. Luego, sea `C` el conjunto resultante de tener cada par `<g, l>`, donde cada una de estos pares representa que la tarea `g` es la tarea que produce el menor valor MDD en la m√°quina `l`).
7. Se puede definir el costo de la funci√≥n de un elemento `<g, l>` en `C` como `c(<g, l>) = MDD(g, l)`.
8. Tambi√©n se define `c_min = min{ c(<g, l>) | <g, l> ‚àà C}` y `c_max = max{ c(<g, l>) | <g, l> ‚àà C}`.
9. Entonces, el `RCL = { <g, l> ‚àà C | c(<g, l>) <= c_min + Œ±(c_max - c_min)}`

### üé∞ GRASP

La implementaci√≥n del algoritmo GRASP recibe la informaci√≥n de las `n` tareas, la cantidad de las `m` m√°quinas, el `alpha` para el RCL y `el m√°ximo n√∫mero de iteraciones`. A continuaci√≥n se describen los pasos de la implementaci√≥n: 

1. El algoritmo empieza a generar una soluci√≥n inicial aleatoria `S`. Por ahora, se tiene que `S` es la mejor soluci√≥n que se tiene para el problema.
2. Ahora, para cada iteraci√≥n, se construye una soluci√≥n voraz aleatoria `S'`, el cual: 

    2.1. Se considera las tareas que a√∫n no han sido programadas y se aplica el enfoque heur√≠stico para la Lista Restringida de Candidatos (RCL). 

    2.2. De esta lista RCL, se escoge aleatoriamente un elemento: `<g, l>`. 

    2.3. Luego, del elemento seleccionado `<g, l>`, se le asigna la tarea `g` a la m√°quina `l`. 

    2.4. Se elimina la tarea `g` de la lista de tareas sin programar en esta soluci√≥n parcial construida `S'`.

    2.5. Se repite los pasos 2.1 a 2.4 hasta que no queden tareas sin programar.
3. Se reemplaza `S` por `S'` si el retraso total o total tardiness de las tareas en la soluci√≥n `S` es mayor que el de `S'`, en caso contrario, no se hace nada.
4. Se repite el paso 2 y 3 hasta que se acaben las iteraciones.

## Definici√≥n de un fenotipo/genotipo, operadores de cruce y mutaci√≥n e implementaci√≥n de un algoritmo gen√©tico.

### üß¨ Genotipo de los individuos para modelado del problema 

Para prop√≥sitos de nuestro problema, definimos un gen como un par ordenado que contiene el identificador num√©rico de un trabajo y el n√∫mero de la m√°quina donde este trabajo est√° asignado en el cronograma que modela su conjunto de genes. Esto es, si tenemos, por ejemplo, la tupla (5, 8), esto representa que el trabajo de ID 5 est√° asignado a la m√°quina 8. Este modelado de un gen se encuentra en el struct `Gene` definido en `evolution.cpp`.

Como por la definici√≥n del problema cada trabajo est√° asignado a una sola m√°quina, para una instancia del mismo con `n` trabajos el genotipo de un individuo viene dado por un vector de `n` genes, donde cada posici√≥n indica la m√°quina a la que est√° asignada cada uno de los trabajos. De esta manera, el genotipo de un individuo est√° restringido en el hecho de que para cada trabajo en la instancia del problema su identificador aparece en el genotipo de un individuo exactamente una vez. En referencia al *orden* que tienen los trabajos dentro de cada m√°quina individual, el mismo viene dado por el orden que tienen los trabajos involucrados dentro del vector genotipo. Esto es, si para un individuo tenemos el vector de genes `[..., (6, 1), ..., (9, 1), ..., (4, 1), ...]` entonces en la m√°quina 1 estar√°n ubicados los trabajos de identificadores 6, 9 y 4 en ese orden.

De esta manera una poblaci√≥n no es m√°s que un arreglo de genotipos, que a su vez son arreglos de genes. Los tipos de datos para la representaci√≥n de un individuo y de una poblaci√≥n se encuentran en los tipos `Individual` y `Population` definidos en `evolution.cpp`.

### üëæ Fenotipo de los individuos y funci√≥n de *fitness*

El fenotipo de los individuos viene dado por el mismo modelo de cronograma utilizado en el primer corte. Esto es, un cronograma es un arreglo multi-dimensional donde cada posici√≥n representa a una de las m√°quinas disponibles, y cada m√°quina es un arreglo de trabajos que indica cu√°les trabajos est√°n asignados a esa m√°quina y en qu√© orden se ejecutar√°n dentro de la misma. La obtensi√≥n del fenotipo de un individuo a trav√©s de su genotipo es prove√≠da por la funci√≥n `get_fenotype` definida en `evolution.cpp`.

La aptitud de un individuo viene dada directamente por la morosidad total de su fenotipo, la cual se calcula de la misma forma presentada en el corte pasado. Como los algoritmos gen√©ticos son inherentemente problemas de maximizaci√≥n, y estamos ante un problema que busca un m√≠nimo global, la definici√≥n espec√≠fica de la aptitud de un individuo viene dada por el negativo de su morosidad total.

### üë®‚Äçüë©‚Äçüë¶ Selecci√≥n de Padres y apareamiento

El algoritmo implementado hace uso de apareamiento con 2 padres. Cada individuo tiene a su vez una probabilidad asociada de ser escogido para ser padre de la siguiente generaci√≥n igual al cociente de su valor para la funci√≥n de aptitud entre la suma total de las aptitudes de todos los individuos. Esto es, si definimos f(i) como la aptitud del individuo i de la poblaci√≥n S, entonces la probabilidad p(i) de que i sea escogido como padre viene dada por:

<center> <code> p(i) = 1 - f(i)/sum(f(j) for j in S) </code> </center>

Tras ser escogidos dos padres, sus descendientes son obtenidos utilizando cruce parcialmente mapeado. Esto debido a que, como cada identificador de trabajo aparece exactamente una vez dentro del genotipo de cualquier individuo, podemos, de cierta manera, tratar los genotipos como permutaciones de los identificadores de los trabajos. 

La selecci√≥n de padres y el operador de cruce vienen dados por las funciones `choose_parents` y `partially_mapped_crossover` definidas en evolution.cpp, respectivamente.

### ‚ò¢Ô∏è Mutaci√≥n

La mutaci√≥n de individuos se realiza con probabilidad uniforme sobre los genes de los mismos. La probabilidad de mutaci√≥n es prove√≠da como argumento de entrada al algoritmo gen√©tico (`mutation_rate`) y no var√≠a de ninguna manera durante la ejecuci√≥n del algoritmo. El operador de mutaci√≥n implementado recibe un gen y reasigna el trabajo encontrado dentro del mismo a otra m√°quina aleatoriamente escogida. El operador de mutaci√≥n no modifica de ninguna manera los identificadores de los trabajos encontrados en los genes ni efect√∫a ning√∫n tipo de reordenamiento sobre los genes del fenotipo.

## üöÄ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./PROY2 <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el n√∫mero del algoritmo a ejecutar:

1. B√∫squeda Local Iterada (ILS)
2. B√∫squeda Tab√∫ 
3. Reconocido Simulado
4. GRASP
5. Algoritmo Gen√©tico

## üìÑ Analisis de resultados

A continuaci√≥n se presenta el an√°lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomar√° en cuenta los valores de tardanza √≥ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados de ambos cortes del proyecto.


### üìä M√©tricas Comparativas
Las m√©tricas claves en el an√°lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la Soluci√≥n √ìptima (Optimal Solution Difference)**: La diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima.
- **Tiempo en segundos (Time in seconds)**: El tiempo en segundos tomado por el algoritmo.

As√≠ mismo, se emplearon diferentes par√°metros para cada algoritmo implementado en este segundo corte:
**Par√°metros del Iterated Local Search (ILS)**:
 * max_iter Cantidad m√°xima de iteraciones para el algoritmo ILS
 * p0 La fuerza de perturbaci√≥n inicial.
 * pmax El multiplicador m√°ximo de fuerza de perturbaci√≥n.
 * lsmax El n√∫mero m√°ximo de iteraciones para el algoritmo de local search dentro de ILS.
 * itermax El n√∫mero m√°ximo de iteraciones antes de aumentar la fuerza de la perturbaci√≥n.

> ILS1: max_iter = 1500, p0 = 10, pmax = 4, lsmax = 100, itermax = 100

> ILS2: max_iter = 1000, p0 = 3, pmax = 15, lsmax = 70, itermax = 150

**Par√°metros del Tabu Search (TS)**:
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo de b√∫squeda tab√∫.
 * max_grn_iter El n√∫mero m√°ximo de iteraciones para generar vecinos dentro de cada iteraci√≥n.
 * tabu_tenure El tama√±o de la lista tab√∫.

> TS1: max_iter = 10000, max_grn_iter = 100, tabu_ternure = 7

> TS2: max_iter = 6000, max_grn_iter = 70, tabu_ternure = 5

**Par√°metros del Simulated Annealing (SA) o Reconocido Simulado**:
 * t0 La temperatura inicial para el algoritmo de recocido simulado.
 * t_step El factor por el cual la temperatura disminuye en cada iteraci√≥n.
 * max_iter_t_step El n√∫mero m√°ximo de iteraciones en cada paso de temperatura.
 * max_iters El n√∫mero m√°ximo de iteraciones para el algoritmo de recocido simulado.

> SA1: t0 = 2000, t_step = 0,90, max_iter_t_step = 100, max_iter = 1500

> SA2: t0 = 1500, t_step = 0,70, max_iter_t_step = 120, max_iter = 1500

> SA3: t0 = 1500, t_step = 0,85, max_iter_t_step = 100, max_iter = 1000

**Par√°metros del GRASP**:
 * max_iters El n√∫mero m√°ximo de iteraciones a realizar.
 * alpha El valor alfa utilizado para calcular la condici√≥n para RCL.

> Grasp 0.25-30: max_iters = 30, alpha = 0.25

> Grasp 0.5-30: max_iters = 30, alpha = 0.5

> Grasp 0.75-30: max_iters = 30, alpha = 0.75

> Grasp 0.25-60: max_iters = 60, alpha = 0.25

> Grasp 0.5-60: max_iters = 60, alpha = 0.5

> Grasp 0.75-60: max_iters = 60, alpha = 0.75

> Grasp 0.25-100: max_iters = 100, alpha = 0.25

> Grasp 0.5-100: max_iters = 100, alpha = 0.5

> Grasp 0.75-100: max_iters = 100, alpha = 0.75


**Par√°metros del Genetic Algorithm (GA) o Algoritmo Gen√©tico**:
 * population_size El tama√±o de la poblaci√≥n para el algoritmo gen√©tico.
 * mutation_rate el porcentaje en que ocurren las mutaciones durante el algoritmo gen√©tico.
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo gen√©tico.

> GA1: population_size = 50, mutation_rate = 5%, max_iter = 4000

> GA2: population_size = 50, mutation_rate = 10%, max_iter = 4000

> GA3: population_size = 100, mutation_rate = 5%, max_iter = 8000

### üìà Resultados
Los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` se encuentran en el directorio `results`, sin embargo, debido a la cantidad de datos obtenidos, se almacen√≥ los datos m√°s relevantes en el siguiente enlace: [Resultados](https://docs.google.com/spreadsheets/d/1hKiU8t9stOFJTKyNNQ1MKPmBr3OwZpMlk57sYdZWiEQ/edit#gid=294798782)

A modo de resumen y para facilitar la visualizaci√≥n de los resultados, se presentan las siguentes im√°genes comparativas resumidas a continuaci√≥n:

#### Promedio de diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima cada n tareas y m m√°quinas
- Resultados del corte anterior:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Diff Opt Corte1](./img/DiffOptCorte1.png)

- Resultados de Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

![Diff Opt ILS &TS &SA](./img/DiffOptILS&TS&SA.png)

- Resultados de GRASP usando diferentes par√°metros:

![Diff Opt GRASP](./img/DiffOptGRASP.png)

- Resultados de Genetic Algorithm (GA) usando diferentes par√°metros:

![Diff Op tGA](./img/DiffOptGA.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20

![Sorted Diff opt by n = 20](./img/SortedDiffn20Corte2.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 25

![Sorted Diff opt by n = 25](./img/SortedDiffn25Corte2.png)

#### Promedio de tiempo en segundos para cada n tareas y m m√°quinas
- Resultados del corte anterior:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Time Corte1](./img/TimeCorte1.png)

- Resultados de Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

![Time ILS & TS & SA](./img/TimeILS&TS&SA.png)

- Resultados de GRASP usando diferentes par√°metros:

![Time GRASP](./img/TimeGRASP.png)

- Resultados de Genetic Algorithm (GA) usando diferentes par√°metros:

![Diff Op tGA](./img/TimeGA.png)

#### Resultados ordenados por promedio de tiempo por n = 20

![Sorted Time by n = 20](./img/SortedTimen20Corte2.png)

#### Resultados ordenados por promedio de tiempo por n = 25

![Sorted Time by n = 25](./img/SortedTimen25Corte2.png)


## üìå Conclusiones

- **Seg√∫n el promedio de diferencias entre la soluci√≥n √≥ptima y la soluci√≥n obtenida**:
    - **Para n = 20** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):
        - *El algoritmo que di√≥ menor diferencia entre las soluciones √≥ptimas y las soluciones obtenidas* es **GRASP con alpha = 0.25** para el RCL **y con un m√°ximo de 100 iteraciones**, cuyo promedio de diferencia es de 1,2071.
        - *El algoritmo que di√≥ mayor diferencia entre las soluciones √≥ptimas y las soluciones obtenidas* es el **Algoritmo Gen√©tico con *population_size = 50, mutation_rate = 10%, max_iter = 4000** con un promedio de diferencia mayor que 150, espec√≠ficamente, 154,81156.
        - Adem√°s, en el caso del algoritmo gen√©tico, vemos que *GA1* y *GA2*, que tienen un promedio de diferencia mayor a 150, est√°n debajos de la b√∫squeda local con soluci√≥n inicial aleatoria que tiene un promedio de diferencia de 117,2631. As√≠ mismo, para este caso n=20, *GA1*, que se diferencia de *GA2* por tener un porcentaje de mutaci√≥n de 5% menos que *GA2*, vemos que *GA1* es mejor en cu√°nto a la diferencia con las soluciones √≥ptimas que *GA2*. Y del uso de los diferentes par√°metros para el algoritmo gen√©tico, vemos que *GA3* (con mayor cantidad de iteraciones y mayor tama√±o de poblaci√≥n con el mismo porcentaje de mutaci√≥n que *GA1*) es mejor que *GA1* y *GA2* e incluso de las soluciones obtenidas con la b√∫squeda local partiendo de la soluci√≥n inicial aleatoria.
        - Luego, **todos los que est√°n encima de *GA3* tienen un promedio de diferencia menor de 20**, siendo *la soluci√≥n heur√≠stica* el que est√° encima de *GA3*.
        - Justamente encima de la soluci√≥n heur√≠stica, se encuentra el algoritmo de *Reconocido Simulado* usando los 3 diferentes par√°metros, vemos que *SA2* tiene menor diferencia con la soluci√≥n √≥ptima en comparaci√≥n con *SA1* y *SA3*, lo que sugiere que aunque *SA2* tiene una temperatura inicial y el t_step (factor el cual la temperatura disminuye en cada iteraci√≥n) menor o igual que las otras dos, lo importante es que tiene un max_iter_t_step mayor (el n√∫mero max de iteraciones en cada paso de temperatura).
        - Para el ILS, se observa que ambos ILSs est√°n justos encima de *SA2*, siendo el mejor entre las dos, el *ILS2*, que aunque tiene menor cantidad de iteraciones m√°ximas para el algoritmo ILS y tambi√©n la menor cantidad de iteraciones para el algoritmo local search que trabaja dentro del ILS, se tiene que produce mejores resultados si el ILS tiene un mayor multiplicador m√°ximo de fuerza de perturbaci√≥n, as√≠ como tambi√©n un mayor n√∫mero de iteraciones antes de aumentar la fuerza de perturbaci√≥n junto con una menor fuerza de perturbaci√≥n inicial. 
        - *Arriba del *ILS2**, se encuentra *la b√∫squeda local a partir de una soluci√≥n inicial heur√≠stica*, con una diferencia con el *ILS2* de 0,89.
        - Las dos b√∫squedas locales, ***TS1* y *TS2* se presentan encima de la soluci√≥n con *b√∫squeda local partiendo de una soluci√≥n inicial heur√≠stica***, el cual *TS2* tiene menos diferencia con las soluciones √≥ptimas que *TS1*. De esto, se sugiere que a pesar de que *TS2* tiene valores menores para la cantidad m√°xima de iteraciones, el n√∫mero m√°ximo de iteraciones para generar vecinos dentro de cada iteraci√≥n (max_gnr_iter) y el n√∫mero de iteraciones durante las cuales un movimiento permanece en la lista tab√∫ (tabu_tenure), una configuraci√≥n m√°s peque√±a en estos par√°metros puede conducir a un mejor rendimiento del algoritmo de b√∫squeda tab√∫.
        - Y por √∫ltimo, las 9 diferentes configuraciones del **algoritmo GRASP** est√°n encima de cualquier otro algoritmo. Y seg√∫n los resultados, parece que **para un alpha peque√±o, como 0.25, ofrece mejores soluciones al problema para cualquier cantidad de iteraciones**.

    - **Para n = 25** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):
        - Para este caso, vemos que **el que ofrece mejores soluciones al problema sigue siendo *el algoritmo GRASP con alpha = 0.25 y un m√°ximo de 100 iteraciones***. 
        - As√≠ mismo, el orden desde *GRASP 0.25-100* hasta *ILS1* permanece igual que para el caso de n = 20.
        - Los √∫ltimos tres de la lista son justamente las tres configuraciones diferentes del algoritmo gen√©tico, el cual tiene un promedio de diferencias mayores que 170, donde *GA3* sigue siendo mejor que *GA1* y *GA2*. Estas √∫ltimas dos tienen un promedio de diferencias mayores que 230. 
        - Sin embargo, ahora *GA3* est√° debajo de la soluci√≥n de b√∫squeda local con soluci√≥n inicial aleatoria. Adem√°s, *GA2* est√° encima de *GA1*, lo cual parece sugerir que para una cantidad de tareas (n) mayor, es preferible tener un porcentaje de mutaci√≥n m√°s grande.
        - **La soluci√≥n heur√≠stica sigue siendo mejor que los algoritmos gen√©ticos y la b√∫squeda local con soluci√≥n inicial aleatoria**.
        - Para el caso de las 3 configuraciones del algoritmo simulado reconocido (SA), las tres siguen estando encima de la soluci√≥n heur√≠stica, pero ahora se tiene que *SA2* est√° debajo tanto de *SA1* como de *SA3*. De estas 3 configuraciones de SA, el mejor es *SA1*, el cual tiene valores mayores para la temperatura inicial, el factor de decremento de la temperatura y el n√∫mero m√°ximo de iteraciones para el algoritmo.

- **Seg√∫n el tiempo promedio de ejecuci√≥n**
    - **Para n=20:**
        - El algoritmo m√°s r√°pido es la heur√≠stica, con un tiempo de 0.00037 segundos, lo que lo hace extremadamente eficiente en t√©rminos de tiempo. *El algoritmo GRASP* presenta un buen balance entre *tiempo de ejecuci√≥n* y *calidad de soluci√≥n*. Por ejemplo, *Grasp 0.25-30* tiene un tiempo de ejecuci√≥n de 0.61 segundos, siendo uno de los m√°s r√°pidos dentro de los GRASP, mientras que *Grasp 0.75-100* es *el m√°s lento dentro de esta categor√≠a* con un tiempo de *2.32 segundos*. Esto sugiere que, aunque incrementar el n√∫mero de iteraciones puede mejorar ligeramente la calidad de la soluci√≥n, *tambi√©n aumenta el tiempo de ejecuci√≥n de manera considerable*.

        - Las ejecuciones del *algoritmo de b√∫squeda tab√∫ (TS1 y TS2)* tienen *tiempos de ejecuci√≥n moderados*, con *TS1* tomando *7.60 segundos* y *TS2 2.82 segundos*. *TS2* es notablemente m√°s r√°pido y tambi√©n produce soluciones de mejor calidad, lo que indica que *una configuraci√≥n de par√°metros m√°s ajustada* puede *mejorar tanto la eficiencia* como *la efectividad del algoritmo* de b√∫squeda tab√∫.

        - *El algoritmo de recocido simulado (SA1, SA2, SA3)* muestra tiempos m√°s altos, especialmente *SA1 y SA2*, que *tienen tiempos de 3.31 y 3.97 segundos* respectivamente.

        - La b√∫squeda local con soluci√≥n inicial heur√≠stica y aleatoria tienen tiempos similares, de 1.35 y 1.38 segundos respectivamente*. Sin embargo, la b√∫squeda local con soluci√≥n inicial heur√≠stica produce soluciones de mejor calidad, lo que sugiere que *el tiempo adicional invertido en una buena soluci√≥n inicial es beneficioso.*

        - *La b√∫squeda local iterativa (ILS1 y ILS2)* *muestra tiempos de 2.41 y 1.07 segundos* respectivamente, con *ILS2 siendo m√°s r√°pido*. Esto indica que configuraciones con menos iteraciones pueden ser m√°s eficientes sin sacrificar mucho en t√©rminos de calidad de soluci√≥n.

        - *El algoritmo gen√©tico es el m√°s lento*, con *GA3 siendo el m√°s lento con un tiempo de 141.46 segundos*. *Las otras configuraciones del algoritmo gen√©tico (GA1 y GA2) tambi√©n son lentas*, con *tiempos de 17.25 y 16.39 segundos respectivamente*, lo que los hace ineficientes para problemas donde el tiempo de ejecuci√≥n es cr√≠tico.

    - **Para n=25:**
        - *La heur√≠stica sigue siendo el algoritmo m√°s r√°pido con un tiempo de 0.00033 segundos.* *El algoritmo GRASP mantiene tiempos de ejecuci√≥n bajos*, con *Grasp 0.25-30* siendo el m√°s r√°pido con *0.31 segundos* y *Grasp 0.75-100 el m√°s lento con 1.24 segundos*. Esto confirma que las configuraciones de GRASP con menos iteraciones son m√°s r√°pidas y a√∫n efectivas, haciendo de GRASP una opci√≥n robusta para diferentes tama√±os de problema.

        - *El algoritmo de b√∫squeda tab√∫ (TS1 y TS2)* tiene *tiempos de ejecuci√≥n de 6.87 y 2.71 segundos respectivamente*. *La reducci√≥n en el tiempo de ejecuci√≥n de TS2 en comparaci√≥n con TS1 sigue siendo significativa*, reforzando la idea de que una configuraci√≥n optimizada del algoritmo de b√∫squeda tab√∫ puede ofrecer grandes mejoras en eficiencia.

        - *El algoritmo de recocido simulado (SA1, SA2, SA3) muestra tiempos moderados, con SA1 y SA2 en 3.33 y 3.96 segundos respectivamente*, mientras que *SA3* con 1,87 segundos, siendo la m√°s r√°pida que las otras dos configuraciones de reconocido simulado.

        - *La b√∫squeda local con soluci√≥n inicial heur√≠stica y aleatoria tienen tiempos de 1.22 segundos cada uno*, manteniendo consistencia en su eficiencia. La b√∫squeda local con soluci√≥n inicial heur√≠stica sigue siendo la mejor opci√≥n por su balance entre tiempo y calidad de la soluci√≥n.

        - *Las configuraciones de b√∫squeda local iterativa (ILS1 y ILS2) muestran tiempos de 2.28 y 0.91 segundos respectivamente*, con *ILS2 siendo nuevamente m√°s r√°pido*. Esto sugiere que ILS2 no solo es m√°s eficiente en t√©rminos de tiempo, sino que tambi√©n mantiene una buena calidad de soluci√≥n.

        - *El algoritmo gen√©ticos sigue siendo el m√°s lento*, con *GA3* *siendo el m√°s lento con un tiempo de 137.34 segundos*. *GA1 y GA2 tambi√©n presentan tiempos altos, con 16.70 y 20.28 segundos respectivamente.* Este alto costo computacional, junto con la menor calidad de soluci√≥n en comparaci√≥n con otros algoritmos, hace que el algoritmo gen√©tico con estas configuraciones sean menos atractivos para este tipo problemas de tama√±o n=25.
    
    **En resumen, GRASP con alpha = 0.25 y 100 iteraciones ofreci√≥ la mejor combinaci√≥n de precisi√≥n y tiempo de ejecuci√≥n, mientras que los algoritmos gen√©ticos fueron los menos eficientes en ambas m√©tricas.**
