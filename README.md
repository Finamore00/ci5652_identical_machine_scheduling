# CI5652 - Identical Machine Scheduling
Proyecto de Dise√±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad Sim√≥n Bol√≠var.

## üìù Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ü§î Descripci√≥n del problema
Dado un conjunto de `n` tareas y `m` m√°quinas id√©nticas, el objetivo es asignar cada tarea a una m√°quina y determinar la secuencia de tareas en cada m√°quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaci√≥n del trabajo `j`.

# üìã INFORME DEL PROYECTO - TERCER CORTE
El programa est√° implementado en C++ y consta de los siguientes archivos para este tercer corte:

- `memetic.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo mem√©tico para el problema.
- `aco.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo de optimicaci√≥n de colonia de hormigas para el problema.

üìÇ En la carpeta `benchmarks` se encuentran los casos de pruebas de la primera corte del proyecto para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## Definici√≥n del operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres, el m√©todo de mejora luego de la recombinaci√≥n y la implementaci√≥n del algoritmo mem√©tico

### üòÇ Algoritmo Mem√©tico ( Õ°¬∞ Õú ñ Õ°¬∞)

### üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶ Operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres

- **Operador de cruce utilizado en el algoritmo gen√©tico**: Cruce parcialmente mapeado.

- **Cruce parcialmente mapeado para m√∫ltiples padres**: Se implementa el cruce parcialmente mapeado para m√∫ltiples padres, cuyo proceso consiste en:

    1. Sea `k` el n√∫mero de padres. 

    2. Se seleccionan aleatoriamente `k` puntos de corte para dividir cada padre en `k + 1` subpartes.

    ![Ejemplo de subpartes](./img/ejemplo_subpartes.png)

    3. Se crea una lista de mapeo (`ch_map`) utilizando la funci√≥n `create_mapping_list`. Esta lista mapea los genes (o tareas) de diferentes padres entre s√≠. 

        3.1. Sea `g` el n√∫mero de genes o tareas de un individuo.

        3.2. Se crea un arreglo `job_mapped` para rastrear qu√© tareas ya han sido mapeados y un contador de tareas mapeados `cnt_mapped`

        3.3. Se selecciona aleatoriamente un padre `start_parent` y un gen inicial del padre seleccionado `start_gene`.

        3.4. Luego se ejecuta un bucle con `g` iteraciones
        
            3.4.1. En el bucle, se marca el gen actual `start_gene` como mapeado.

            3.4.2. Se selecciona un padre final `end_parent` aleatoriamente y diferente del padre inicial y se busca en el padre final el gen que corresponde a la misma tarea que el gen inicial, al encontrarlo se guarda el gen en `end_gene`.

            3.4.3. Se incrementa `cnt_mapped` a 1. Si todos las tareas han sido mapeados, se sale del bucle.

            3.4.4. Si a√∫n faltan tareas por mapear, se elige un nuevo padre inicial diferente del final y se selecciona un nuevo gen inicial cuya tarea no haya sido mapeada a√∫n.

            3.4.5. Y se agrega un mapeo con `ch_map[end_gene.job->id] = start_gene`

        3.5. Despu√©s del bucle, se agrega un mapeo final de la tarea del √∫ltimo gen a la tarea del gen inicial (el primer gen que se mapea). Esto para crear un mapeo c√≠clico entre tareas.

        ![Mapeo de genes](./img/mapeo_genes.png)

    4. Luego, se crea un orden aleatorio en los genes para cada subparte con la funci√≥n `create_random_order` y este orden aleatorio se guarda en un arreglo `order`

    5. Se crean los `k` hijos.

    6. Primero cada hijo `i` se copia la primera subparte del padre `i` (antes del primer punto de corte y despu√©s del √∫ltimo punto de corte).

    7. Luego, para cada hijo `i`, las subpartes entre los puntos de corte se copian de otros padres en un patr√≥n diagonal.

    8. Posteriormente, se legaliza cada hijo para asegurar que no hayan trabajos duplicados.

        8.1. Se crea un nuevo orden aleatorio `new_order` para procesar las subpartes del hijo `i`.

        8.2. Se marcan inicialmente la primera subparte procesada, o sea, la primera subparte de cada hijo permanece igual.

        8.3. Para cada subparte restante seg√∫n el orden en `new_order`.

            8.3.1. Se revisa cada gen de la subparte actual seg√∫n el orden en `order`.

            8.3.2. Si la tarea ya est√° marcado (duplicado), se reemplaza con el trabajo mapeado seg√∫n la lista de mapeo (`ch_map`). Este proceso contin√∫a hasta encontrar un trabajo no marcado.
            
            8.3.3. Al encontrar un trabajo no marcado, se marca el nuevo trabajo y se actualiza el gen en el hijo actual.

        8.4. Se verifica que todas las tareas est√©n marcadas (para asegurar que no hayan tareas duplicadas y tampoco tareas faltantes).

    9. Se devuelven los hijos generados.

### üöÄ‚¨Ü Mejora luego de la recombinaci√≥n

Para este paso, se utiliza la b√∫squeda local implementada en la primera corte del proyecto.

1. Sea un hijo `h` producido en la recombinaci√≥n.

2. Se decodifica el genotipo del hijo `h` en un fenotipo v√°lido.

3. Luego, se le aplica la b√∫squeda local al fenotipo convertido.

4. Y por √∫ltimo, el resultado de la b√∫squeda local se transforma nuevamente en un genotipo.

### üõ†Ô∏è Par√°metros del algoritmo mem√©tico

Aparte de recibir las tareas y la cantidad de m√°quinas, y los par√°metros del algoritmo gen√©tico: 
- population_size: El tama√±o de la poblaci√≥n

- mutation_rate: El porcentaje de mutaci√≥n.

- max_iter: El m√°ximo n√∫mero de iteraciones o generaciones.

El algoritmo mem√©tico recibe adicionalmente los siguientes par√°metros:
- nro_parents_crossover: Un entero para la cantidad de padres para ser seleccionadas para la recombinaci√≥n en cada generaci√≥n.

- opt_freq: Un entero que indica la frequencia de aplicar la mejora con la b√∫squeda local. Responde a la pregunta de ¬øcada cu√°ntas generaciones se lanza la optimizaci√≥n?

- opt_rate: Un float para el porcentaje de aplicar la mejora en la b√∫squeda local sobre los descendientes. ¬øCu√°ntos invididuos generados son optimizados en cada generaci√≥n?

- random_opt_rate: Un valor booleano que indica si aplicar la b√∫squeda local con un porcentaje aleatorio en  cada generaci√≥n o aplicarlo seg√∫n el opt_rate. Y si es aleatorio, el valor del par√°metro es true, en caso contrario es false. Adem√°s, si es aleatorio, el valor de porcentaje para la b√∫squeda local en cada generaci√≥n debe ser mayor que 10%, esto para asegurar que siempre se aplique una cantidad significativa de optimizaci√≥n local.

### üë£ Proceso del algoritmo mem√©tico

Los primeros pasos del algoritmo mem√©tico son similares al algoritmo gen√©tico de la segunda corte del proyecto:

1. Se genera una poblaci√≥n aleatoria inicial.

2. Se ordena la poblaci√≥n por su fitness.

3. Luego, se comienza un bucle. Hasta que se terminen el m√°ximo n√∫mero de generaciones o se encuentre la soluci√≥n √≥ptima (un fitness igual a 0), se procede a: 

    3.1. Calcular el fitness de cada individuo y la suma del fitness total de la poblaci√≥n.

    3.2. Crear una nueva poblaci√≥n, el cual se generan nuevos individuos hasta llenar el 90% de la nueva poblaci√≥n. El 10% restante se completa con los mejores individuos de la poblaci√≥n anterior.

Ac√° el paso 3.2. cambia un poco para el algoritmo mem√©tico:

3.2.1. Se seleccionan m√∫ltiples padres usando la funci√≥n `choose_multi_parents`. La selecci√≥n de padres es la misma condici√≥n para el algoritmo gen√©tico.
> Si definimos f(i) como la aptitud del individuo i de la poblaci√≥n S, entonces la probabilidad p(i) de que i sea escogido como padre viene dada por: p(i) = 1 - f(i)/sum(f(j) for j in S) 

3.2.2. Se aplica el cruce parcialmente mapeado multi-parental.

Luego del paso 3.2, se continua dentro del bucle con los siguientes pasos:

3.3. Se aplica mutaci√≥n a los nuevos individuos generados 
> Mutaci√≥n: Reasigna el trabajo seleccionado dentro de una m√°quina a otra m√°quina aleatoriamente escogida.

3.4. Se optimiza la generaci√≥n si es que le toca optimizarse (`opt_freq`):
- Se determina cu√°ntos individuos optimizar (basado en `random_opt_rate` y `opt_rate`).
- Se aplica b√∫squeda local a los individuos seleccionados.

3.5. La nueva poblaci√≥n reemplaza a la anterior.

3.6. Se ordena la nueva poblaci√≥n por su aptitud o fitness.

3.7. Se repite desde el paso 3.1 a 3.6 hasta que se finalice el bucle.

## Definici√≥n del comportamiento de la feromona/heur√≠stica e implemente con ello una optimizaci√≥n de colonia de hormigas
### üêú Optimizaci√≥n de Colonia de Hormigas

#### Feromona 

- **Estructura**: Se implementa como una matriz bidimensional donde cada elemento œÑ[i][j] representa el nivel de feromona para asignar la tarea i a la m√°quina j.

- **Inicializaci√≥n**: Al comenzar, todos los valores de feromona se establecen en 1.0, indicando que inicialmente no hay preferencia por ninguna asignaci√≥n.

- **Actualizaci√≥n local**: Despu√©s de cada asignaci√≥n de tarea, se actualiza la feromona usando la f√≥rmula:
  œÑ[job][machine] = (1 - œÅ_local) * œÑ[job][machine] + œÅ_local * ŒîœÑ
  Donde ŒîœÑ es 1 dividido por el retraso m√°ximo calculado inicialmente y œÅ_local es un par√°metro que controla la tasa de evaporaci√≥n local.

- **Actualizaci√≥n global**: Al final de cada iteraci√≥n, se actualiza la feromona bas√°ndose en la mejor soluci√≥n encontrada:
  œÑ[i][j] = (1 - œÅ_global) * œÑ[i][j] + œÅ_global * (1 / mejor_retraso) 
    Donde œÅ_global es un par√°metro que controla la tasa de evaporaci√≥n global y mejor_retraso es el retraso total de la mejor soluci√≥n encontrada.

- **Uso**: En la selecci√≥n de tareas, la feromona se eleva a la potencia Œ± para ajustar su influencia en la decisi√≥n.

#### Heur√≠stica


- **C√°lculo**: Se define como el inverso del retraso modificado de la fecha de vencimiento (modified due date tardiness o MDD):
  Œ∑ = 1 / MDD(tiempo_actual_m√°quina, tarea)

- **Funci√≥n MDD**: Calcula el retraso potencial de una tarea si se asignara a una m√°quina en un momento dado. 

- **Uso**: En la selecci√≥n de tareas, la heur√≠stica se eleva a la potencia Œ≤ para ajustar su influencia en la decisi√≥n.

- **Equilibrio con la feromona**: La probabilidad de seleccionar una tarea para una m√°quina se calcula como:
  P[i][j] ‚àù (œÑ[i][j])^Œ± * (Œ∑[i][j])^Œ≤
  Donde œÑ es la feromona, Œ∑ es la heur√≠stica, y Œ± y Œ≤ son par√°metros que controlan la importancia relativa de la feromona y la heur√≠stica respectivamente.

Esta combinaci√≥n de feromona y heur√≠stica permite al algoritmo equilibrar entre explotar la informaci√≥n aprendida (a trav√©s de la feromona) y responder a las caracter√≠sticas espec√≠ficas de cada tarea y el estado actual de las m√°quinas (a trav√©s de la heur√≠stica). Esto gu√≠a al algoritmo hacia soluciones que minimizan el retraso total de las tareas, adapt√°ndose din√°micamente a medida que construye y mejora las soluciones.

#### Pasos del Algoritmo

1. **Inicializaci√≥n**

El algoritmo comienza creando la matriz de feromonas. Adem√°s, se calcula el MDD Tardiness que se usa como referencia para la actualizaci√≥n local de la feromona. 

2. **Ciclo principal**

El coraz√≥n del algoritmo es un ciclo que se repite un n√∫mero fijo de veces. Cada repetici√≥n de este ciclo representa una generaci√≥n completa de soluciones. Durante cada iteraci√≥n, el algoritmo generar√° una soluci√≥n, la mejorar√°, y usar√° la informaci√≥n obtenida para influir en las siguientes generaciones.

3. **Construcci√≥n de soluciones**

En esta fase, el algoritmo crea m√∫ltiples soluciones desde cero. Cada soluci√≥n se construye de manera similar a c√≥mo una hormiga construir√≠a un camino. Se comienza con todas las tareas sin asignar y todas las m√°quinas vac√≠as. Luego, para cada tarea, se selecciona primero una m√°quina, favoreciendo aquellas con menos tiempo de procesamiento acumulado. Despu√©s, se elige una tarea para esa m√°quina, bas√°ndose en los niveles de feromona (que indican qu√© tan buena ha sido esta asignaci√≥n en el pasado) y la urgencia de la tarea. Una vez hecha la asignaci√≥n, se actualiza el tiempo de procesamiento de la m√°quina y se modifica ligeramente el nivel de feromona para esa combinaci√≥n espec√≠fica de tarea y m√°quina.

4. **Actualizaci√≥n local de feromonas**

Despu√©s de asignar cada tarea a una m√°quina, el algoritmo actualiza los niveles de feromona localmente. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que se han asignado en esta soluci√≥n.

5. **Mejora local**

Una vez construida una soluci√≥n completa, el algoritmo intenta mejorarla. Esto se hace mediante un proceso de b√∫squeda local.

6. **Evaluaci√≥n**

Despu√©s de mejorar cada soluci√≥n, el algoritmo calcula su calidad midiendo el retraso total que produce. Si esta soluci√≥n resulta ser mejor que la mejor encontrada hasta ahora (es decir, si produce un retraso total menor), se guarda como la nueva mejor soluci√≥n. 

7. **Actualizaci√≥n global de feromonas**

Al final de cada iteraci√≥n, despu√©s de haber construido y evaluado todas las soluciones de esa generaci√≥n, el algoritmo actualiza la matriz de feromonas bas√°ndose en la mejor soluci√≥n encontrada. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que aparecen en la mejor soluci√≥n.

8. **Evaporaci√≥n de feromonas**

Para evitar que el algoritmo se quede atrapado en soluciones sub√≥ptimas, se implementa un mecanismo de evaporaci√≥n de feromonas. Esto significa que en cada iteraci√≥n, todos los niveles de feromona se reducen ligeramente.

9. **Finalizaci√≥n**

Despu√©s de completar todas las iteraciones programadas, el algoritmo termina y devuelve la mejor soluci√≥n que ha encontrado. Esta soluci√≥n representa la programaci√≥n de tareas que, seg√∫n el algoritmo, deber√≠a producir el menor retraso total posible dado el conjunto de tareas y m√°quinas disponibles.

## üöÄ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./PROY3 <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el n√∫mero del algoritmo a ejecutar:

1. Algoritmo Mem√©tico
2. B√∫squeda Dispersa
3. Optimizaci√≥n de Colonia de Hormigas

## üìÑ Analisis de resultados

A continuaci√≥n se presenta el an√°lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomar√° en cuenta los valores de tardanza √≥ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados de ambos cortes del proyecto.


### üìä M√©tricas Comparativas
Las m√©tricas claves en el an√°lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la Soluci√≥n √ìptima (Optimal Solution Difference)**: La diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima.
- **Tiempo en segundos (Time in seconds)**: El tiempo en segundos tomado por el algoritmo.

As√≠ mismo, se emplearon diferentes par√°metros para cada algoritmo implementado en este segundo corte:
**Par√°metros del Iterated Local Search (ILS)**:
 * max_iter Cantidad m√°xima de iteraciones para el algoritmo ILS
 * p0 La fuerza de perturbaci√≥n inicial.
 * pmax El multiplicador m√°ximo de fuerza de perturbaci√≥n.
 * lsmax El n√∫mero m√°ximo de iteraciones para el algoritmo de local search dentro de ILS.
 * itermax El n√∫mero m√°ximo de iteraciones antes de aumentar la fuerza de la perturbaci√≥n.

> ILS1: max_iter = 1500, p0 = 10, pmax = 4, lsmax = 100, itermax = 100

> ILS2: max_iter = 1000, p0 = 3, pmax = 15, lsmax = 70, itermax = 150

**Par√°metros del Tabu Search (TS)**:
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo de b√∫squeda tab√∫.
 * max_grn_iter El n√∫mero m√°ximo de iteraciones para generar vecinos dentro de cada iteraci√≥n.
 * tabu_tenure El tama√±o de la lista tab√∫.

> TS1: max_iter = 10000, max_grn_iter = 100, tabu_ternure = 7

> TS2: max_iter = 6000, max_grn_iter = 70, tabu_ternure = 5

**Par√°metros del Simulated Annealing (SA) o Reconocido Simulado**:
 * t0 La temperatura inicial para el algoritmo de recocido simulado.
 * t_step El factor por el cual la temperatura disminuye en cada iteraci√≥n.
 * max_iter_t_step El n√∫mero m√°ximo de iteraciones en cada paso de temperatura.
 * max_iters El n√∫mero m√°ximo de iteraciones para el algoritmo de recocido simulado.

> SA1: t0 = 2000, t_step = 0,90, max_iter_t_step = 100, max_iter = 1500

> SA2: t0 = 1500, t_step = 0,70, max_iter_t_step = 120, max_iter = 1500

> SA3: t0 = 1500, t_step = 0,85, max_iter_t_step = 100, max_iter = 1000

**Par√°metros del GRASP**:
 * max_iters El n√∫mero m√°ximo de iteraciones a realizar.
 * alpha El valor alfa utilizado para calcular la condici√≥n para RCL.

> Grasp 0.25-30: max_iters = 30, alpha = 0.25

> Grasp 0.5-30: max_iters = 30, alpha = 0.5

> Grasp 0.75-30: max_iters = 30, alpha = 0.75

> Grasp 0.25-60: max_iters = 60, alpha = 0.25

> Grasp 0.5-60: max_iters = 60, alpha = 0.5

> Grasp 0.75-60: max_iters = 60, alpha = 0.75

> Grasp 0.25-100: max_iters = 100, alpha = 0.25

> Grasp 0.5-100: max_iters = 100, alpha = 0.5

> Grasp 0.75-100: max_iters = 100, alpha = 0.75


**Par√°metros del Genetic Algorithm (GA) o Algoritmo Gen√©tico**:
 * population_size El tama√±o de la poblaci√≥n para el algoritmo gen√©tico.
 * mutation_rate el porcentaje en que ocurren las mutaciones durante el algoritmo gen√©tico.
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo gen√©tico.

> GA1: population_size = 50, mutation_rate = 5%, max_iter = 4000

> GA2: population_size = 50, mutation_rate = 10%, max_iter = 4000

> GA3: population_size = 100, mutation_rate = 5%, max_iter = 8000

### üìà Resultados
Los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` se encuentran en el directorio `results`, sin embargo, debido a la cantidad de datos obtenidos, se almacen√≥ los datos m√°s relevantes en el siguiente enlace: [Resultados](https://docs.google.com/spreadsheets/d/1hKiU8t9stOFJTKyNNQ1MKPmBr3OwZpMlk57sYdZWiEQ/edit#gid=294798782)

A modo de resumen y para facilitar la visualizaci√≥n de los resultados, se presentan las siguentes im√°genes comparativas resumidas a continuaci√≥n:

#### Promedio de diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima cada n tareas y m m√°quinas
- Resultados del corte anterior:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Diff Opt Corte1](./img/DiffOptCorte1.png)

- Resultados de Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

![Diff Opt ILS &TS &SA](./img/DiffOptILS&TS&SA.png)

- Resultados de GRASP usando diferentes par√°metros:

![Diff Opt GRASP](./img/DiffOptGRASP.png)

- Resultados de Genetic Algorithm (GA) usando diferentes par√°metros:

![Diff Op tGA](./img/DiffOptGA.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20

![Sorted Diff opt by n = 20](./img/SortedDiffn20Corte2.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 25

![Sorted Diff opt by n = 25](./img/SortedDiffn25Corte2.png)

#### Promedio de tiempo en segundos para cada n tareas y m m√°quinas
- Resultados del corte anterior:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Time Corte1](./img/TimeCorte1.png)

- Resultados de Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

![Time ILS & TS & SA](./img/TimeILS&TS&SA.png)

- Resultados de GRASP usando diferentes par√°metros:

![Time GRASP](./img/TimeGRASP.png)

- Resultados de Genetic Algorithm (GA) usando diferentes par√°metros:

![Diff Op tGA](./img/TimeGA.png)

#### Resultados ordenados por promedio de tiempo por n = 20

![Sorted Time by n = 20](./img/SortedTimen20Corte2.png)

#### Resultados ordenados por promedio de tiempo por n = 25

![Sorted Time by n = 25](./img/SortedTimen25Corte2.png)


## üìå Conclusiones

- **Seg√∫n el promedio de diferencias entre la soluci√≥n √≥ptima y la soluci√≥n obtenida**:
    - **Para n = 20** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):
        - *El algoritmo que di√≥ menor diferencia entre las soluciones √≥ptimas y las soluciones obtenidas* es **GRASP con alpha = 0.25** para el RCL **y con un m√°ximo de 100 iteraciones**, cuyo promedio de diferencia es de 1,2071.
        - *El algoritmo que di√≥ mayor diferencia entre las soluciones √≥ptimas y las soluciones obtenidas* es el **Algoritmo Gen√©tico con *population_size = 50, mutation_rate = 10%, max_iter = 4000** con un promedio de diferencia mayor que 150, espec√≠ficamente, 154,81156.
        - Adem√°s, en el caso del algoritmo gen√©tico, vemos que *GA1* y *GA2*, que tienen un promedio de diferencia mayor a 150, est√°n debajos de la b√∫squeda local con soluci√≥n inicial aleatoria que tiene un promedio de diferencia de 117,2631. As√≠ mismo, para este caso n=20, *GA1*, que se diferencia de *GA2* por tener un porcentaje de mutaci√≥n de 5% menos que *GA2*, vemos que *GA1* es mejor en cu√°nto a la diferencia con las soluciones √≥ptimas que *GA2*. Y del uso de los diferentes par√°metros para el algoritmo gen√©tico, vemos que *GA3* (con mayor cantidad de iteraciones y mayor tama√±o de poblaci√≥n con el mismo porcentaje de mutaci√≥n que *GA1*) es mejor que *GA1* y *GA2* e incluso de las soluciones obtenidas con la b√∫squeda local partiendo de la soluci√≥n inicial aleatoria.
        - Luego, **todos los que est√°n encima de *GA3* tienen un promedio de diferencia menor de 20**, siendo *la soluci√≥n heur√≠stica* el que est√° encima de *GA3*.
        - Justamente encima de la soluci√≥n heur√≠stica, se encuentra el algoritmo de *Reconocido Simulado* usando los 3 diferentes par√°metros, vemos que *SA2* tiene menor diferencia con la soluci√≥n √≥ptima en comparaci√≥n con *SA1* y *SA3*, lo que sugiere que aunque *SA2* tiene una temperatura inicial y el t_step (factor el cual la temperatura disminuye en cada iteraci√≥n) menor o igual que las otras dos, lo importante es que tiene un max_iter_t_step mayor (el n√∫mero max de iteraciones en cada paso de temperatura).
        - Para el ILS, se observa que ambos ILSs est√°n justos encima de *SA2*, siendo el mejor entre las dos, el *ILS2*, que aunque tiene menor cantidad de iteraciones m√°ximas para el algoritmo ILS y tambi√©n la menor cantidad de iteraciones para el algoritmo local search que trabaja dentro del ILS, se tiene que produce mejores resultados si el ILS tiene un mayor multiplicador m√°ximo de fuerza de perturbaci√≥n, as√≠ como tambi√©n un mayor n√∫mero de iteraciones antes de aumentar la fuerza de perturbaci√≥n junto con una menor fuerza de perturbaci√≥n inicial. 
        - *Arriba del *ILS2**, se encuentra *la b√∫squeda local a partir de una soluci√≥n inicial heur√≠stica*, con una diferencia con el *ILS2* de 0,89.
        - Las dos b√∫squedas locales, ***TS1* y *TS2* se presentan encima de la soluci√≥n con *b√∫squeda local partiendo de una soluci√≥n inicial heur√≠stica***, el cual *TS2* tiene menos diferencia con las soluciones √≥ptimas que *TS1*. De esto, se sugiere que a pesar de que *TS2* tiene valores menores para la cantidad m√°xima de iteraciones, el n√∫mero m√°ximo de iteraciones para generar vecinos dentro de cada iteraci√≥n (max_gnr_iter) y el n√∫mero de iteraciones durante las cuales un movimiento permanece en la lista tab√∫ (tabu_tenure), una configuraci√≥n m√°s peque√±a en estos par√°metros puede conducir a un mejor rendimiento del algoritmo de b√∫squeda tab√∫.
        - Y por √∫ltimo, las 9 diferentes configuraciones del **algoritmo GRASP** est√°n encima de cualquier otro algoritmo. Y seg√∫n los resultados, parece que **para un alpha peque√±o, como 0.25, ofrece mejores soluciones al problema para cualquier cantidad de iteraciones**.

    - **Para n = 25** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):
        - Para este caso, vemos que **el que ofrece mejores soluciones al problema sigue siendo *el algoritmo GRASP con alpha = 0.25 y un m√°ximo de 100 iteraciones***. 
        - As√≠ mismo, el orden desde *GRASP 0.25-100* hasta *ILS1* permanece igual que para el caso de n = 20.
        - Los √∫ltimos tres de la lista son justamente las tres configuraciones diferentes del algoritmo gen√©tico, el cual tiene un promedio de diferencias mayores que 170, donde *GA3* sigue siendo mejor que *GA1* y *GA2*. Estas √∫ltimas dos tienen un promedio de diferencias mayores que 230. 
        - Sin embargo, ahora *GA3* est√° debajo de la soluci√≥n de b√∫squeda local con soluci√≥n inicial aleatoria. Adem√°s, *GA2* est√° encima de *GA1*, lo cual parece sugerir que para una cantidad de tareas (n) mayor, es preferible tener un porcentaje de mutaci√≥n m√°s grande.
        - **La soluci√≥n heur√≠stica sigue siendo mejor que los algoritmos gen√©ticos y la b√∫squeda local con soluci√≥n inicial aleatoria**.
        - Para el caso de las 3 configuraciones del algoritmo simulado reconocido (SA), las tres siguen estando encima de la soluci√≥n heur√≠stica, pero ahora se tiene que *SA2* est√° debajo tanto de *SA1* como de *SA3*. De estas 3 configuraciones de SA, el mejor es *SA1*, el cual tiene valores mayores para la temperatura inicial, el factor de decremento de la temperatura y el n√∫mero m√°ximo de iteraciones para el algoritmo.

- **Seg√∫n el tiempo promedio de ejecuci√≥n**
    - **Para n=20:**
        - El algoritmo m√°s r√°pido es la heur√≠stica, con un tiempo de 0.00037 segundos, lo que lo hace extremadamente eficiente en t√©rminos de tiempo. *El algoritmo GRASP* presenta un buen balance entre *tiempo de ejecuci√≥n* y *calidad de soluci√≥n*. Por ejemplo, *Grasp 0.25-30* tiene un tiempo de ejecuci√≥n de 0.61 segundos, siendo uno de los m√°s r√°pidos dentro de los GRASP, mientras que *Grasp 0.75-100* es *el m√°s lento dentro de esta categor√≠a* con un tiempo de *2.32 segundos*. Esto sugiere que, aunque incrementar el n√∫mero de iteraciones puede mejorar ligeramente la calidad de la soluci√≥n, *tambi√©n aumenta el tiempo de ejecuci√≥n de manera considerable*.

        - Las ejecuciones del *algoritmo de b√∫squeda tab√∫ (TS1 y TS2)* tienen *tiempos de ejecuci√≥n moderados*, con *TS1* tomando *7.60 segundos* y *TS2 2.82 segundos*. *TS2* es notablemente m√°s r√°pido y tambi√©n produce soluciones de mejor calidad, lo que indica que *una configuraci√≥n de par√°metros m√°s ajustada* puede *mejorar tanto la eficiencia* como *la efectividad del algoritmo* de b√∫squeda tab√∫.

        - *El algoritmo de recocido simulado (SA1, SA2, SA3)* muestra tiempos m√°s altos, especialmente *SA1 y SA2*, que *tienen tiempos de 3.31 y 3.97 segundos* respectivamente.

        - La b√∫squeda local con soluci√≥n inicial heur√≠stica y aleatoria tienen tiempos similares, de 1.35 y 1.38 segundos respectivamente*. Sin embargo, la b√∫squeda local con soluci√≥n inicial heur√≠stica produce soluciones de mejor calidad, lo que sugiere que *el tiempo adicional invertido en una buena soluci√≥n inicial es beneficioso.*

        - *La b√∫squeda local iterativa (ILS1 y ILS2)* *muestra tiempos de 2.41 y 1.07 segundos* respectivamente, con *ILS2 siendo m√°s r√°pido*. Esto indica que configuraciones con menos iteraciones pueden ser m√°s eficientes sin sacrificar mucho en t√©rminos de calidad de soluci√≥n.

        - *El algoritmo gen√©tico es el m√°s lento*, con *GA3 siendo el m√°s lento con un tiempo de 141.46 segundos*. *Las otras configuraciones del algoritmo gen√©tico (GA1 y GA2) tambi√©n son lentas*, con *tiempos de 17.25 y 16.39 segundos respectivamente*, lo que los hace ineficientes para problemas donde el tiempo de ejecuci√≥n es cr√≠tico.

    - **Para n=25:**
        - *La heur√≠stica sigue siendo el algoritmo m√°s r√°pido con un tiempo de 0.00033 segundos.* *El algoritmo GRASP mantiene tiempos de ejecuci√≥n bajos*, con *Grasp 0.25-30* siendo el m√°s r√°pido con *0.31 segundos* y *Grasp 0.75-100 el m√°s lento con 1.24 segundos*. Esto confirma que las configuraciones de GRASP con menos iteraciones son m√°s r√°pidas y a√∫n efectivas, haciendo de GRASP una opci√≥n robusta para diferentes tama√±os de problema.

        - *El algoritmo de b√∫squeda tab√∫ (TS1 y TS2)* tiene *tiempos de ejecuci√≥n de 6.87 y 2.71 segundos respectivamente*. *La reducci√≥n en el tiempo de ejecuci√≥n de TS2 en comparaci√≥n con TS1 sigue siendo significativa*, reforzando la idea de que una configuraci√≥n optimizada del algoritmo de b√∫squeda tab√∫ puede ofrecer grandes mejoras en eficiencia.

        - *El algoritmo de recocido simulado (SA1, SA2, SA3) muestra tiempos moderados, con SA1 y SA2 en 3.33 y 3.96 segundos respectivamente*, mientras que *SA3* con 1,87 segundos, siendo la m√°s r√°pida que las otras dos configuraciones de reconocido simulado.

        - *La b√∫squeda local con soluci√≥n inicial heur√≠stica y aleatoria tienen tiempos de 1.22 segundos cada uno*, manteniendo consistencia en su eficiencia. La b√∫squeda local con soluci√≥n inicial heur√≠stica sigue siendo la mejor opci√≥n por su balance entre tiempo y calidad de la soluci√≥n.

        - *Las configuraciones de b√∫squeda local iterativa (ILS1 y ILS2) muestran tiempos de 2.28 y 0.91 segundos respectivamente*, con *ILS2 siendo nuevamente m√°s r√°pido*. Esto sugiere que ILS2 no solo es m√°s eficiente en t√©rminos de tiempo, sino que tambi√©n mantiene una buena calidad de soluci√≥n.

        - *El algoritmo gen√©ticos sigue siendo el m√°s lento*, con *GA3* *siendo el m√°s lento con un tiempo de 137.34 segundos*. *GA1 y GA2 tambi√©n presentan tiempos altos, con 16.70 y 20.28 segundos respectivamente.* Este alto costo computacional, junto con la menor calidad de soluci√≥n en comparaci√≥n con otros algoritmos, hace que el algoritmo gen√©tico con estas configuraciones sean menos atractivos para este tipo problemas de tama√±o n=25.
    
    **En resumen, GRASP con alpha = 0.25 y 100 iteraciones ofreci√≥ la mejor combinaci√≥n de precisi√≥n y tiempo de ejecuci√≥n, mientras que los algoritmos gen√©ticos fueron los menos eficientes en ambas m√©tricas.**
