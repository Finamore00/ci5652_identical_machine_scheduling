# CI5652 - Identical Machine Scheduling
Proyecto de Dise√±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad Sim√≥n Bol√≠var.

## üìù Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ü§î Descripci√≥n del problema
Dado un conjunto de `n` tareas y `m` m√°quinas id√©nticas, el objetivo es asignar cada tarea a una m√°quina y determinar la secuencia de tareas en cada m√°quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaci√≥n del trabajo `j`.

# üìã INFORME DEL PROYECTO - TERCER CORTE
El programa est√° implementado en C++ y consta de los siguientes archivos para este tercer corte:

- `memetic.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo mem√©tico para el problema.
- `aco.cpp`: Archivo principal del programa que contiene la implementaci√≥n de una soluci√≥n utilizando el algoritmo de optimicaci√≥n de colonia de hormigas para el problema.

üìÇ En la carpeta `benchmarks` se encuentran los casos de pruebas de la primera corte del proyecto para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## Definici√≥n del operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres, el m√©todo de mejora luego de la recombinaci√≥n y la implementaci√≥n del algoritmo mem√©tico

### üòÇ Algoritmo Mem√©tico ( Õ°¬∞ Õú ñ Õ°¬∞)

### üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶üë®‚Äçüë©‚Äçüë¶ Operador de cruce utilizado en el algoritmo gen√©tico para una recombinaci√≥n de al menos 3 padres

- **Operador de cruce utilizado en el algoritmo gen√©tico**: Cruce parcialmente mapeado.

- **Cruce parcialmente mapeado para m√∫ltiples padres**: Se implementa el cruce parcialmente mapeado para m√∫ltiples padres, cuyo proceso consiste en:

    1. Sea `k` el n√∫mero de padres. 

    2. Se seleccionan aleatoriamente `k` puntos de corte para dividir cada padre en `k + 1` subpartes. 

    ![Ejemplo de subpartes](./img/ejemplo_subpartes.png)

      La √∫ltima subparte lo vamos a tomar en cuenta como subparte 1 tambi√©n.

    3. Se crea una lista de mapeo (`ch_map`) utilizando la funci√≥n `create_mapping_list`. Esta lista mapea los genes (o tareas) de diferentes padres entre s√≠. 

        3.1. Sea `g` el n√∫mero de genes o tareas de un individuo.

        3.2. Se crea un arreglo `job_mapped` para rastrear qu√© tareas ya han sido mapeados y un contador de tareas mapeados `cnt_mapped`

        3.3. Se selecciona aleatoriamente un padre `start_parent` y un gen inicial del padre seleccionado `start_gene`.

        3.4. Luego se ejecuta un bucle con `g` iteraciones
        
            3.4.1. En el bucle, se marca el gen actual `start_gene` como mapeado.

            3.4.2. Se selecciona un padre final `end_parent` aleatoriamente y diferente del padre inicial y se busca en el padre final el gen que corresponde a la misma tarea que el gen inicial, al encontrarlo se guarda el gen en `end_gene`.

            3.4.3. Se incrementa `cnt_mapped` a 1. Si todos las tareas han sido mapeados, se sale del bucle.

            3.4.4. Si a√∫n faltan tareas por mapear, se elige un nuevo padre inicial diferente del final y se selecciona un nuevo gen inicial cuya tarea no haya sido mapeada a√∫n.

            3.4.5. Y se agrega un mapeo con `ch_map[end_gene.job->id] = start_gene`

        3.5. Despu√©s del bucle, se agrega un mapeo final de la tarea del √∫ltimo gen a la tarea del gen inicial (el primer gen que se mapea). Esto para crear un mapeo c√≠clico entre tareas.

        ![Mapeo de genes](./img/mapeo_genes.png)

    4. Luego, se crea un orden aleatorio en los genes para cada subparte con la funci√≥n `create_random_order` y este orden aleatorio se guarda en un arreglo `order`

    5. Se crean los `k` hijos.

    6. Primero cada hijo `i` se copia la primera subparte del padre `i` (antes del primer punto de corte y despu√©s del √∫ltimo punto de corte).

    7. Luego, para cada hijo `i`, las subpartes entre los puntos de corte se copian de otros padres en un patr√≥n diagonal.

    8. Posteriormente, se legaliza cada hijo para asegurar que no hayan trabajos duplicados.

        8.1. Se crea un nuevo orden aleatorio `new_order` para procesar las subpartes del hijo `i`.

        8.2. Se marcan inicialmente la primera subparte procesada, o sea, la primera subparte de cada hijo permanece igual.

        8.3. Para cada subparte restante seg√∫n el orden en `new_order`.

            8.3.1. Se revisa cada gen de la subparte actual seg√∫n el orden en `order`.

            8.3.2. Si la tarea ya est√° marcado (duplicado), se reemplaza con el trabajo mapeado seg√∫n la lista de mapeo (`ch_map`). Este proceso contin√∫a hasta encontrar un trabajo no marcado.
            
            8.3.3. Al encontrar un trabajo no marcado, se marca el nuevo trabajo y se actualiza el gen en el hijo actual.

        8.4. Se verifica que todas las tareas est√©n marcadas (para asegurar que no hayan tareas duplicadas y tampoco tareas faltantes).

    9. Se devuelven los hijos generados.

### üöÄ‚¨Ü Mejora luego de la recombinaci√≥n

Para este paso, se utiliza la b√∫squeda local implementada en la primera corte del proyecto.

1. Sea un hijo `h` producido en la recombinaci√≥n.

2. Se decodifica el genotipo del hijo `h` en un fenotipo v√°lido.

3. Luego, se le aplica la b√∫squeda local al fenotipo convertido.

4. Y por √∫ltimo, el resultado de la b√∫squeda local se transforma nuevamente en un genotipo.

### üõ†Ô∏è Par√°metros del algoritmo mem√©tico

Aparte de recibir las tareas y la cantidad de m√°quinas, y los par√°metros del algoritmo gen√©tico: 
- population_size: El tama√±o de la poblaci√≥n

- mutation_rate: El porcentaje de mutaci√≥n.

- max_iter: El m√°ximo n√∫mero de iteraciones o generaciones.

El algoritmo mem√©tico recibe adicionalmente los siguientes par√°metros:
- nro_parents_crossover: Un entero para la cantidad de padres para ser seleccionadas para la recombinaci√≥n en cada generaci√≥n.

- opt_freq: Un entero que indica la frequencia de aplicar la mejora con la b√∫squeda local. Responde a la pregunta de ¬øcada cu√°ntas generaciones se lanza la optimizaci√≥n?

- opt_rate: Un float para el porcentaje de aplicar la mejora en la b√∫squeda local sobre los descendientes. ¬øCu√°ntos invididuos generados son optimizados en cada generaci√≥n?

- random_opt_rate: Un valor booleano que indica si aplicar la b√∫squeda local con un porcentaje aleatorio en  cada generaci√≥n o aplicarlo seg√∫n el opt_rate. Y si es aleatorio, el valor del par√°metro es true, en caso contrario es false. Adem√°s, si es aleatorio, el valor de porcentaje para la b√∫squeda local en cada generaci√≥n debe ser mayor que 10%, esto para asegurar que siempre se aplique una cantidad significativa de optimizaci√≥n local.

### üë£ Pasos del algoritmo mem√©tico

Los primeros pasos del algoritmo mem√©tico son similares al algoritmo gen√©tico de la segunda corte del proyecto:

1. Se genera una poblaci√≥n aleatoria inicial.

2. Se ordena la poblaci√≥n por su fitness.

3. Luego, se comienza un bucle. Hasta que se terminen el m√°ximo n√∫mero de generaciones o se encuentre la soluci√≥n √≥ptima (un fitness igual a 0), se procede a: 

    3.1. Calcular el fitness de cada individuo y la suma del fitness total de la poblaci√≥n.

    3.2. Crear una nueva poblaci√≥n, el cual se generan nuevos individuos hasta llenar el 90% de la nueva poblaci√≥n. El 10% restante se completa con los mejores individuos de la poblaci√≥n anterior.

Ac√° el paso 3.2. cambia un poco para el algoritmo mem√©tico:

3.2.1. Se seleccionan m√∫ltiples padres usando la funci√≥n `choose_multi_parents`. La selecci√≥n de padres es la misma condici√≥n para el algoritmo gen√©tico.
> Si definimos f(i) como la aptitud del individuo i de la poblaci√≥n S, entonces la probabilidad p(i) de que i sea escogido como padre viene dada por: p(i) = 1 - f(i)/sum(f(j) for j in S) 

3.2.2. Se aplica el cruce parcialmente mapeado multi-parental.

Luego del paso 3.2, se continua dentro del bucle con los siguientes pasos:

3.3. Se aplica mutaci√≥n a los nuevos individuos generados 
> Mutaci√≥n: Reasigna el trabajo seleccionado dentro de una m√°quina a otra m√°quina aleatoriamente escogida.

3.4. Se optimiza la generaci√≥n si es que le toca optimizarse (`opt_freq`):
- Se determina cu√°ntos individuos optimizar (basado en `random_opt_rate` y `opt_rate`).
- Se aplica b√∫squeda local a los individuos seleccionados.

3.5. La nueva poblaci√≥n reemplaza a la anterior.

3.6. Se ordena la nueva poblaci√≥n por su aptitud o fitness.

3.7. Se repite desde el paso 3.1 a 3.6 hasta que se finalice el bucle.

## Definici√≥n de la medida de distancia entre soluciones, el re-enlazado de caminos para un porcentaje dado de los pares de puntos de referencia de cada "generaci√≥n", e implementaci√≥n del algoritmo de b√∫squeda dispersa.

### üîç Algoritmo de B√∫squeda Dispersa

...........................

## Definici√≥n del comportamiento de la feromona/heur√≠stica e implemente con ello una optimizaci√≥n de colonia de hormigas
### üêú Optimizaci√≥n de Colonia de Hormigas

#### Feromona 

- **Estructura**: Se implementa como una matriz bidimensional donde cada elemento œÑ[i][j] representa el nivel de feromona para asignar la tarea i a la m√°quina j.

- **Inicializaci√≥n**: Al comenzar, todos los valores de feromona se establecen en 1.0, indicando que inicialmente no hay preferencia por ninguna asignaci√≥n.

- **Actualizaci√≥n local**: Despu√©s de cada asignaci√≥n de tarea, se actualiza la feromona usando la f√≥rmula:
  œÑ[job][machine] = (1 - œÅ_local) * œÑ[job][machine] + œÅ_local * ŒîœÑ
  Donde ŒîœÑ es 1 dividido por el retraso m√°ximo calculado inicialmente y œÅ_local es un par√°metro que controla la tasa de evaporaci√≥n local.

- **Actualizaci√≥n global**: Al final de cada iteraci√≥n, se actualiza la feromona bas√°ndose en la mejor soluci√≥n encontrada:
  œÑ[i][j] = (1 - œÅ_global) * œÑ[i][j] + œÅ_global * (1 / mejor_retraso) 
    Donde œÅ_global es un par√°metro que controla la tasa de evaporaci√≥n global y mejor_retraso es el retraso total de la mejor soluci√≥n encontrada.

- **Uso**: En la selecci√≥n de tareas, la feromona se eleva a la potencia Œ± para ajustar su influencia en la decisi√≥n.

#### Heur√≠stica


- **C√°lculo**: Se define como el inverso del retraso modificado de la fecha de vencimiento (modified due date tardiness o MDD):
  Œ∑ = 1 / MDD(tiempo_actual_m√°quina, tarea)

- **Funci√≥n MDD**: Calcula el retraso potencial de una tarea si se asignara a una m√°quina en un momento dado. 

- **Uso**: En la selecci√≥n de tareas, la heur√≠stica se eleva a la potencia Œ≤ para ajustar su influencia en la decisi√≥n.

- **Equilibrio con la feromona**: La probabilidad de seleccionar una tarea para una m√°quina se calcula como:
  P[i][j] ‚àù (œÑ[i][j])^Œ± * (Œ∑[i][j])^Œ≤
  Donde œÑ es la feromona, Œ∑ es la heur√≠stica, y Œ± y Œ≤ son par√°metros que controlan la importancia relativa de la feromona y la heur√≠stica respectivamente.

Esta combinaci√≥n de feromona y heur√≠stica permite al algoritmo equilibrar entre explotar la informaci√≥n aprendida (a trav√©s de la feromona) y responder a las caracter√≠sticas espec√≠ficas de cada tarea y el estado actual de las m√°quinas (a trav√©s de la heur√≠stica). Esto gu√≠a al algoritmo hacia soluciones que minimizan el retraso total de las tareas, adapt√°ndose din√°micamente a medida que construye y mejora las soluciones.

#### Pasos del Algoritmo

1. **Inicializaci√≥n**

El algoritmo comienza creando la matriz de feromonas. Adem√°s, se calcula el MDD Tardiness que se usa como referencia para la actualizaci√≥n local de la feromona. 

2. **Ciclo principal**

El coraz√≥n del algoritmo es un ciclo que se repite un n√∫mero fijo de veces. Cada repetici√≥n de este ciclo representa una generaci√≥n completa de soluciones. Durante cada iteraci√≥n, el algoritmo generar√° una soluci√≥n, la mejorar√°, y usar√° la informaci√≥n obtenida para influir en las siguientes generaciones.

3. **Construcci√≥n de soluciones**

En esta fase, el algoritmo crea m√∫ltiples soluciones desde cero. Cada soluci√≥n se construye de manera similar a c√≥mo una hormiga construir√≠a un camino. Se comienza con todas las tareas sin asignar y todas las m√°quinas vac√≠as. Luego, para cada tarea, se selecciona primero una m√°quina, favoreciendo aquellas con menos tiempo de procesamiento acumulado. Despu√©s, se elige una tarea para esa m√°quina, bas√°ndose en los niveles de feromona (que indican qu√© tan buena ha sido esta asignaci√≥n en el pasado) y la urgencia de la tarea. Una vez hecha la asignaci√≥n, se actualiza el tiempo de procesamiento de la m√°quina y se modifica ligeramente el nivel de feromona para esa combinaci√≥n espec√≠fica de tarea y m√°quina.

4. **Actualizaci√≥n local de feromonas**

Despu√©s de asignar cada tarea a una m√°quina, el algoritmo actualiza los niveles de feromona localmente. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que se han asignado en esta soluci√≥n.

5. **Mejora local**

Una vez construida una soluci√≥n completa, el algoritmo intenta mejorarla. Esto se hace mediante un proceso de b√∫squeda local.

6. **Evaluaci√≥n**

Despu√©s de mejorar cada soluci√≥n, el algoritmo calcula su calidad midiendo el retraso total que produce. Si esta soluci√≥n resulta ser mejor que la mejor encontrada hasta ahora (es decir, si produce un retraso total menor), se guarda como la nueva mejor soluci√≥n. 

7. **Actualizaci√≥n global de feromonas**

Al final de cada iteraci√≥n, despu√©s de haber construido y evaluado todas las soluciones de esa generaci√≥n, el algoritmo actualiza la matriz de feromonas bas√°ndose en la mejor soluci√≥n encontrada. Esto se hace aumentando los niveles de feromona para las combinaciones de tarea-m√°quina que aparecen en la mejor soluci√≥n.

8. **Evaporaci√≥n de feromonas**

Para evitar que el algoritmo se quede atrapado en soluciones sub√≥ptimas, se implementa un mecanismo de evaporaci√≥n de feromonas. Esto significa que en cada iteraci√≥n, todos los niveles de feromona se reducen ligeramente.

9. **Finalizaci√≥n**

Despu√©s de completar todas las iteraciones programadas, el algoritmo termina y devuelve la mejor soluci√≥n que ha encontrado. Esta soluci√≥n representa la programaci√≥n de tareas que, seg√∫n el algoritmo, deber√≠a producir el menor retraso total posible dado el conjunto de tareas y m√°quinas disponibles.

## üöÄ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./PROY3 <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el n√∫mero del algoritmo a ejecutar:

1. Algoritmo Mem√©tico
2. B√∫squeda Dispersa
3. Optimizaci√≥n de Colonia de Hormigas

## üìÑ Analisis de resultados

A continuaci√≥n se presenta el an√°lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomar√° en cuenta los valores de tardanza √≥ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados de ambos cortes del proyecto.


### üìä M√©tricas Comparativas
Las m√©tricas claves en el an√°lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la Soluci√≥n √ìptima (Optimal Solution Difference)**: La diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima.
- **Tiempo en segundos (Time in seconds)**: El tiempo en segundos tomado por el algoritmo.

As√≠ mismo, se emplearon diferentes par√°metros para cada algoritmo implementado en este segundo corte:
**Par√°metros del Iterated Local Search (ILS)**:
 * max_iter Cantidad m√°xima de iteraciones para el algoritmo ILS
 * p0 La fuerza de perturbaci√≥n inicial.
 * pmax El multiplicador m√°ximo de fuerza de perturbaci√≥n.
 * lsmax El n√∫mero m√°ximo de iteraciones para el algoritmo de local search dentro de ILS.
 * itermax El n√∫mero m√°ximo de iteraciones antes de aumentar la fuerza de la perturbaci√≥n.

> ILS1: max_iter = 1500, p0 = 10, pmax = 4, lsmax = 100, itermax = 100

> ILS2: max_iter = 1000, p0 = 3, pmax = 15, lsmax = 70, itermax = 150

**Par√°metros del Tabu Search (TS)**:
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo de b√∫squeda tab√∫.
 * max_grn_iter El n√∫mero m√°ximo de iteraciones para generar vecinos dentro de cada iteraci√≥n.
 * tabu_tenure El tama√±o de la lista tab√∫.

> TS1: max_iter = 10000, max_grn_iter = 100, tabu_ternure = 7

> TS2: max_iter = 6000, max_grn_iter = 70, tabu_ternure = 5

**Par√°metros del Simulated Annealing (SA) o Reconocido Simulado**:
 * t0 La temperatura inicial para el algoritmo de recocido simulado.
 * t_step El factor por el cual la temperatura disminuye en cada iteraci√≥n.
 * max_iter_t_step El n√∫mero m√°ximo de iteraciones en cada paso de temperatura.
 * max_iters El n√∫mero m√°ximo de iteraciones para el algoritmo de recocido simulado.

> SA1: t0 = 2000, t_step = 0,90, max_iter_t_step = 100, max_iter = 1500

> SA2: t0 = 1500, t_step = 0,70, max_iter_t_step = 120, max_iter = 1500

> SA3: t0 = 1500, t_step = 0,85, max_iter_t_step = 100, max_iter = 1000

**Par√°metros del GRASP**:
 * max_iters El n√∫mero m√°ximo de iteraciones a realizar.
 * alpha El valor alfa utilizado para calcular la condici√≥n para RCL.

> Grasp 0.25-30: max_iters = 30, alpha = 0.25

> Grasp 0.5-30: max_iters = 30, alpha = 0.5

> Grasp 0.75-30: max_iters = 30, alpha = 0.75

> Grasp 0.25-60: max_iters = 60, alpha = 0.25

> Grasp 0.5-60: max_iters = 60, alpha = 0.5

> Grasp 0.75-60: max_iters = 60, alpha = 0.75

> Grasp 0.25-100: max_iters = 100, alpha = 0.25

> Grasp 0.5-100: max_iters = 100, alpha = 0.5

> Grasp 0.75-100: max_iters = 100, alpha = 0.75


**Par√°metros del Genetic Algorithm (GA) o Algoritmo Gen√©tico**:
 * population_size El tama√±o de la poblaci√≥n para el algoritmo gen√©tico.
 * mutation_rate el porcentaje en que ocurren las mutaciones durante el algoritmo gen√©tico.
 * max_iter El n√∫mero m√°ximo de iteraciones para el algoritmo gen√©tico.

> GA1: population_size = 50, mutation_rate = 5%, max_iter = 4000

> GA2: population_size = 50, mutation_rate = 10%, max_iter = 4000

> GA3: population_size = 100, mutation_rate = 5%, max_iter = 8000

### üìà Resultados
Los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` se encuentran en el directorio `results`, sin embargo, debido a la cantidad de datos obtenidos, se almacen√≥ los datos m√°s relevantes en el siguiente enlace: [Resultados](https://docs.google.com/spreadsheets/d/1uta3jDjtNU2J74XQsV7Od8gzj1OaBIcp_lE5jGSw7Gw/edit#gid=294798782)

A modo de resumen y para facilitar la visualizaci√≥n de los resultados, se presentan las siguentes im√°genes comparativas resumidas a continuaci√≥n:

#### Promedio de diferencia entre la soluci√≥n obtenida y la soluci√≥n √≥ptima cada n tareas y m m√°quinas
- Resultados del primer corte:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Diff Opt Corte1](./img/DiffOptCorte1.png)

- Resultados del segundo corte:
    - Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

    ![Diff Opt ILS &TS &SA](./img/DiffOptILS&TS&SA.png)

    - GRASP usando diferentes par√°metros:

    ![Diff Opt GRASP](./img/DiffOptGRASP.png)

    - Genetic Algorithm (GA) usando diferentes par√°metros:

    ![Diff Op tGA](./img/DiffOptGA.png)

- Resultados del tercer corte: 

    - Algoritmo Mem√©tico usando diferentes par√°metros:


    - B√∫squeda Dispersa usando diferentes par√°metros:


    - Optimizaci√≥n de Colonia de Hormigas usando diferentes par√°metros:


#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20

![Sorted Diff opt by n = 20](./img/SortedDiffn20Corte3.png)

#### Resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 25

![Sorted Diff opt by n = 25](./img/SortedDiffn25Corte3.png)

#### Promedio de tiempo en segundos para cada n tareas y m m√°quinas
- Resultados del primer corte:
    - Soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n heur√≠stica
    
    - Soluci√≥n de b√∫squeda local partiendo de una soluci√≥n aleatoria.

![Time Corte1](./img/TimeCorte1.png)

- Resultados del segundo corte:

    - Iterated Local Search (ILS), Tabu Search (TS) y Simulated Annealing (SA) usando diferentes par√°metros:

    ![Time ILS & TS & SA](./img/TimeILS&TS&SA.png)

    - GRASP usando diferentes par√°metros:

    ![Time GRASP](./img/TimeGRASP.png)

    - Genetic Algorithm (GA) usando diferentes par√°metros:

    ![Diff Op tGA](./img/TimeGA.png)


- Resultados del tercer corte: 

    - Algoritmo Mem√©tico usando diferentes par√°metros:


    - B√∫squeda Dispersa usando diferentes par√°metros:


    - Optimizaci√≥n de Colonia de Hormigas usando diferentes par√°metros:


#### Resultados ordenados por promedio de tiempo por n = 20

![Sorted Time by n = 20](./img/SortedTimen20Corte3.png)

#### Resultados ordenados por promedio de tiempo por n = 25

![Sorted Time by n = 25](./img/SortedTimen25Corte3.png)


## üìå Conclusiones

- **Seg√∫n el promedio de diferencias entre la soluci√≥n √≥ptima y la soluci√≥n obtenida**:
    - **Para n = 20** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):

    - **Para n = 25** (segun la lista de resultados ordenados por promedio de diferencias entre la soluci√≥n obtenida y la soluci√≥n √≥ptima por n = 20):

- **Seg√∫n el tiempo promedio de ejecuci√≥n**
    - **Para n=20:**
        
    - **Para n=25:**

## üìö Referencias

1. [C. Ting, C. Su and C. Lee. Multi-parent extension of partially mapped crossover for combinatorial optimization problems. Expert Systems with Applications 37, p. 1879‚Äì1886, 2010.](https://mx.nthu.edu.tw/~ckting/pubs/eswa2010.pdf)
