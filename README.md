# CI5652 - Identical Machine Scheduling
Proyecto de DiseÃ±o de Algoritmos II (CI5652) con soluciones aproximadas para el problema de Identical Machine Scheduling. Trimestre Abr-Jul 2024. Universidad SimÃ³n BolÃ­var.

## ğŸ“ Integrantes
- Ana Shek (19-10096)
- Santiago Finamore (18-10125)
- Jeamhowards Montiel (19-10234)

# ğŸ¤” DescripciÃ³n del problema
Dado un conjunto de `n` tareas y `m` mÃ¡quinas idÃ©nticas, el objetivo es asignar cada tarea a una mÃ¡quina y determinar la secuencia de tareas en cada mÃ¡quina de manera que se minimice la tardanza total (the total tardiness). Cada tarea `j` tiene un tiempo de procesamiento `p_j` y una fecha de vencimiento `d_j`. La tardanza de una tarea se calcula como `max(0, C_j - d_j)`, donde `C_j` es el tiempo de finalizaciÃ³n del trabajo `j`.

# ğŸ“‹ INFORME DEL PROYECTO - SEGUNDO CORTE
El programa estÃ¡ implementado en C++ y consta de los siguientes archivos para este segundo corte:

- `grasp.cpp`: Archivo principal del programa que contiene la implementaciÃ³n de una soluciÃ³n utilizando GRASP para el problema.

ğŸ“‚ En la carpeta `benchmarks` se encuentran los casos de pruebas de la primera corte del proyecto para medir y comparar el rendimiento de diferentes algoritmos para solucionar el problema descrito.

## DefiniciÃ³n de una perturbaciÃ³n e implementaciÃ³n de una bÃºsqueda local iterada (ILS).

## DefiniciÃ³n de reglas para movimientos que han de ser tabÃºs e implementaciÃ³n de una bÃºsqueda tabÃº.

## DefiniciÃ³n de un proceso de enfriado progresivo e implementaciÃ³n de un reconocido simulado.

## ğŸ² DefiniciÃ³n de un mÃ©todo de construciÃ³n para una RCL e implementaciÃ³n de GRASP.

### ğŸ‘¨â€âš–ï¸ MÃ©todo de construciÃ³n para una RCL

Para la definiciÃ³n del RCL en este problema, se utilizÃ³ el enfoque heurÃ­stico Modified Due Date (MDD) explicado en el primer corte del proyecto:

1. Sea `S` una soluciÃ³n parcialmente construida.
2. Se tiene una lista de tareas no programadas `U` en la soluciÃ³n `S`.
3. Para cada mÃ¡quina `j`, dividir `U` en dos subconjuntos `U1j` y `U2j` para `j` = 1, 2, ..., `m`.
    > `U1j` contiene las tareas que no se pueden completar en su fecha de vencimiento en la mÃ¡quina `j`.

    > `U2j` contiene las tareas que sÃ­ se pueden completar antes de su fecha de vencimiento en la mÃ¡quina `j`.
4. De `U1j` y `U2j`, encontrar los subconjuntos `Î³j` y `Î»j` que contienen las tareas con el tiempo de procesamiento mÃ­nimo y la fecha de vencimiento mÃ­nima, respectivamente. 
5. Seleccionar una tarea `gj` de `Î³j` o `Î»j` que minimice el valor de MDD en la mÃ¡quina `j`. El valor de MDD en la mÃ¡quina `j` de una tarea `i` estÃ¡ dada por `MDD(j, i) = max(Cj + pi, di)` 
    > `Cj` es la suma del procesamiento de tiempo de las tareas que ya han sido programados en la mÃ¡quina `j`.

    > `pi` es el tiempo de procesamiento de la tarea `i` con su fecha de vencimiento `di`.
6. Luego, sea `C` el conjunto resultante de tener cada par `<g, l>` (la tarea `g` es la tarea que produce el menor valor MDD en la mÃ¡quina `l`).
7. Se puede definir el costo de la funciÃ³n de un elemento `<g, l>` en `C` como `c(<g, l>) = MDD(g, l)`.
8. TambiÃ©n se define `c_min = min{ c(<g, l>) | <g, l> âˆˆ C}` y `c_max = max{ c(<g, l>) | <g, l> âˆˆ C}`.
9. Entonces, el `RCL = { <g, l> âˆˆ C | c(<g, l>) <= c_min + Î±(c_max - c_min)}`

### ğŸ° GRASP

La implementaciÃ³n del algoritmo GRASP recibe la informaciÃ³n de las `n` tareas, la cantidad de las `m` mÃ¡quinas, el `alpha` para el RCL y `el mÃ¡ximo nÃºmero de iteraciones`, y a continuaciÃ³n se describen los pasos de la implementaciÃ³n: 

1. El algoritmo empieza a generar una soluciÃ³n inicial aleatoria `S`. Por ahora, se tiene que `S` es la mejor soluciÃ³n que se tiene para el problema.
2. Ahora, para cada iteraciÃ³n, se construye una soluciÃ³n voraz aleatoria `S'`, el cual: 
    2.1. Se considera las tareas que aÃºn no han sido programadas y se aplica el enfoque heurÃ­stico para la Lista Restringida de Candidatos (RCL). 
    2.2. De esta lista RCL, se escoge aleatoriamente un elemento: `<g, l>`. 
    2.3. Luego, de la tupla seleccionada `<g, l>`, se le asigna la tarea `g` en la mÃ¡quina `l`. 
    2.4. Se elimina la tarea `g` de la lista de tareas sin programar en esta soluciÃ³n parcial construida `S'`.
    2.5. Se repite los pasos 2.1 a 2.4 hasta que no queden tareas sin programar.
3. Se reemplaza `S` por `S'` si el retraso total o total tardiness de las tareas en la soluciÃ³n `S` es mayor que el de `S'`, en caso contrario, no se hace nada.
4. Se repite el paso 2 y 3 hasta que se acaben las iteraciones.

## DefiniciÃ³n de un fenotipo/genotipo, operadores de cruce y mutaciÃ³n e implementaciÃ³n de un algoritmo genÃ©tico.

## ğŸš€ Uso

Para compilar y ejecutar el programa, se debe ejecutar los siguientes comandos en la terminal:

```bash
make
```

```bash
cd target
```

```bash
./PROY2 <path_to_benchmarks> <algorithm>
```

Donde `<path_to_benchmarks>` es la ruta a la carpeta que contiene los casos de prueba y `<algorithm>` es el nÃºmero del algoritmo a ejecutar:

1. BÃºsqueda Local Iterada (ILS)
2. BÃºsqueda TabÃº 
3. Reconocido Simulado
4. GRASP
5. Algoritmo GenÃ©tico

## ğŸ“„ Analisis de resultados

A continuaciÃ³n se presenta el anÃ¡lisis de los resultados obtenidos al ejecutar el programa con los casos de prueba en la carpeta `benchmarks` en una **laptop** con **procesador AMD Ryzen 5 5500U**, **disco SSD**, **8GB de memoria RAM** y **WSL 2 Ubuntu**. Se tomarÃ¡ en cuenta los valores de tardanza Ã³ptima obtenidos del paper de referencia de donde se obtuvo el `benchmark` para comparar los resultados obtenidos con los algoritmos implementados.


### ğŸ“Š MÃ©tricas Comparativas

Las mÃ©tricas claves en el anÃ¡lisis incluyen:

- **Tardanza Total (Total Tardiness)**: La suma de las tardanzas de todas las tareas.
- **Diferencia con la SoluciÃ³n Ã“ptima (Optimal Solution Difference)**: La diferencia entre la soluciÃ³n obtenida y la soluciÃ³n Ã³ptima.

### ğŸ“ˆ Resultados


## ğŸ“Œ Conclusiones



## ğŸ“š Referencias
